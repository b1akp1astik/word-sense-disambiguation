{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOA7Nu7cujGgOx4b3/dgAc4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"e2aef6561a2a434c9a9977c48d168905":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a1131fe7d4f4f70a10452757722a469","IPY_MODEL_52f25ef211364d14854afee7bfa583c0","IPY_MODEL_c60e39146f0e4521ac2a97dafe3feee6"],"layout":"IPY_MODEL_8aee71a1f76742069b1aa0aab6887b94"}},"6a1131fe7d4f4f70a10452757722a469":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_06d5df3f8b424377a159fc9820f9d408","placeholder":"​","style":"IPY_MODEL_3db5e0288dd84f82968c5b00debd30dc","value":"modules.json: 100%"}},"52f25ef211364d14854afee7bfa583c0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d05dc2ec3784509af1cbe0918c7879e","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f82559008c448a1b028971245385130","value":349}},"c60e39146f0e4521ac2a97dafe3feee6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0da02308f3b4dcd9e1ae908755ed22e","placeholder":"​","style":"IPY_MODEL_1ef45e58544c427bae53388295e1fa32","value":" 349/349 [00:00&lt;00:00, 21.4kB/s]"}},"8aee71a1f76742069b1aa0aab6887b94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06d5df3f8b424377a159fc9820f9d408":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3db5e0288dd84f82968c5b00debd30dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7d05dc2ec3784509af1cbe0918c7879e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f82559008c448a1b028971245385130":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0da02308f3b4dcd9e1ae908755ed22e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ef45e58544c427bae53388295e1fa32":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72a0d339c18c4bd7baa18c9dc2d421e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a8c85ee2d674fc88f71a6456bb2b7f4","IPY_MODEL_5f4124847de94032a3151e31f94f2195","IPY_MODEL_e3a691ef12cd4b9ba731eff9c5794e21"],"layout":"IPY_MODEL_7c381e786b52471884e5bbe0313702f4"}},"7a8c85ee2d674fc88f71a6456bb2b7f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb5a65b77cf40e3b7c4b455fc2813f4","placeholder":"​","style":"IPY_MODEL_c6fa59bf785849229c064afa1bff6c9d","value":"config_sentence_transformers.json: 100%"}},"5f4124847de94032a3151e31f94f2195":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4ee6d1d14094401ba4ff7b5f17ade10","max":116,"min":0,"orientation":"horizontal","style":"IPY_MODEL_882bbcf9e4234efeb388a2b43e6efd74","value":116}},"e3a691ef12cd4b9ba731eff9c5794e21":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e6666c748bc44d1badcfffb03d6ac99","placeholder":"​","style":"IPY_MODEL_dc9c948de8a64e0ba00179b7ebe6ed46","value":" 116/116 [00:00&lt;00:00, 10.2kB/s]"}},"7c381e786b52471884e5bbe0313702f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aeb5a65b77cf40e3b7c4b455fc2813f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c6fa59bf785849229c064afa1bff6c9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4ee6d1d14094401ba4ff7b5f17ade10":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"882bbcf9e4234efeb388a2b43e6efd74":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e6666c748bc44d1badcfffb03d6ac99":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc9c948de8a64e0ba00179b7ebe6ed46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b8282393fdf4326a4f796b5d768c39a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfdbc1c40b28495e8922348cdc313228","IPY_MODEL_2fd6d4da38bb4f5dba8d08556b1d06b7","IPY_MODEL_e65c00d265444634b523bdd15ea77520"],"layout":"IPY_MODEL_f5c616bc62c249b4a9c89869fac30b7c"}},"dfdbc1c40b28495e8922348cdc313228":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d56d92eed85f4a63a11531f05211e84e","placeholder":"​","style":"IPY_MODEL_c3ebb119ab0b49179661e39871607b84","value":"README.md: 100%"}},"2fd6d4da38bb4f5dba8d08556b1d06b7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_582ff85b19764f86a1caf4751317ed2d","max":10467,"min":0,"orientation":"horizontal","style":"IPY_MODEL_eb636833c13f4aaebbc2799dc353364b","value":10467}},"e65c00d265444634b523bdd15ea77520":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54b9fb0c077f4083ba0241baf8d047e4","placeholder":"​","style":"IPY_MODEL_eabd79997a024e56aadca46d42690d11","value":" 10.5k/10.5k [00:00&lt;00:00, 858kB/s]"}},"f5c616bc62c249b4a9c89869fac30b7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d56d92eed85f4a63a11531f05211e84e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3ebb119ab0b49179661e39871607b84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"582ff85b19764f86a1caf4751317ed2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb636833c13f4aaebbc2799dc353364b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"54b9fb0c077f4083ba0241baf8d047e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eabd79997a024e56aadca46d42690d11":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f3a2d9f207f46359bb6a9555aa44ae7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9722870c0cf24a47a3c386c475346039","IPY_MODEL_2e54be1f814340e9b9d8fbabcc74e160","IPY_MODEL_067fbf2862e8442898f6ae91561e2863"],"layout":"IPY_MODEL_325c31f6ae0c4f879073194bfe57b65b"}},"9722870c0cf24a47a3c386c475346039":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ce5070989754e46a89a0c69fd0f126c","placeholder":"​","style":"IPY_MODEL_389a2678e67d491fab53dae1f9b21f3b","value":"sentence_bert_config.json: 100%"}},"2e54be1f814340e9b9d8fbabcc74e160":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65c1237961d847ed8006c0e1874b5f78","max":53,"min":0,"orientation":"horizontal","style":"IPY_MODEL_60999e2c74e74da98128777c0f48b394","value":53}},"067fbf2862e8442898f6ae91561e2863":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffe17880f4a143d3a34e56134026570e","placeholder":"​","style":"IPY_MODEL_da6e646e88a44e57a4e6160815c8f7ff","value":" 53.0/53.0 [00:00&lt;00:00, 4.06kB/s]"}},"325c31f6ae0c4f879073194bfe57b65b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ce5070989754e46a89a0c69fd0f126c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"389a2678e67d491fab53dae1f9b21f3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65c1237961d847ed8006c0e1874b5f78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60999e2c74e74da98128777c0f48b394":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ffe17880f4a143d3a34e56134026570e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da6e646e88a44e57a4e6160815c8f7ff":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd4bb4228eed43c48d785dfd2280dc5c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ee6dd10c40d24454b547863f45813210","IPY_MODEL_c49d284a32ff41a4b569494d38674b2e","IPY_MODEL_f10b7876ba3c464dbe483114fe61179a"],"layout":"IPY_MODEL_1eebe580c793400595e32e40448e7d45"}},"ee6dd10c40d24454b547863f45813210":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d89169fac22e404dae51fa564e05303c","placeholder":"​","style":"IPY_MODEL_c269c1ce992a4933a77a5e78a687953d","value":"config.json: 100%"}},"c49d284a32ff41a4b569494d38674b2e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_43e08efa964f4aa5a572bc635db41b63","max":615,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87759f0b579c4299adc5e9897b2700da","value":615}},"f10b7876ba3c464dbe483114fe61179a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07609d889c0848c187647f7cc7c8d9e3","placeholder":"​","style":"IPY_MODEL_832b407b5e4e4335a9843c1d638eb4a6","value":" 615/615 [00:00&lt;00:00, 56.6kB/s]"}},"1eebe580c793400595e32e40448e7d45":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d89169fac22e404dae51fa564e05303c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c269c1ce992a4933a77a5e78a687953d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43e08efa964f4aa5a572bc635db41b63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87759f0b579c4299adc5e9897b2700da":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"07609d889c0848c187647f7cc7c8d9e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"832b407b5e4e4335a9843c1d638eb4a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca070066a4884658ad140dbc582141b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ceb5aa89099640b9ad855de251d51e46","IPY_MODEL_d14a59a4123849528ebcb40c5b2b4b25","IPY_MODEL_e1f623f7efa246e7a917e62efaa7f667"],"layout":"IPY_MODEL_bcaeb5bc8b9b4254838a80f5061cd5ac"}},"ceb5aa89099640b9ad855de251d51e46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e0b7f12904e4bd4a668f046d9ec1ae6","placeholder":"​","style":"IPY_MODEL_a282f3eebfc142159aecf6e4f704413c","value":"model.safetensors: 100%"}},"d14a59a4123849528ebcb40c5b2b4b25":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_684bebbe281a48e9bfb2879ebd234640","max":133466304,"min":0,"orientation":"horizontal","style":"IPY_MODEL_395a8a3987d14b0aa157cb956641c7a2","value":133466304}},"e1f623f7efa246e7a917e62efaa7f667":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dfffe6c323bb4cc8a2932a6fbbf31d2a","placeholder":"​","style":"IPY_MODEL_dde3af8c433342edb11d3899d37e7856","value":" 133M/133M [00:00&lt;00:00, 176MB/s]"}},"bcaeb5bc8b9b4254838a80f5061cd5ac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8e0b7f12904e4bd4a668f046d9ec1ae6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a282f3eebfc142159aecf6e4f704413c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"684bebbe281a48e9bfb2879ebd234640":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"395a8a3987d14b0aa157cb956641c7a2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dfffe6c323bb4cc8a2932a6fbbf31d2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dde3af8c433342edb11d3899d37e7856":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a272b0fa8fc242ce93c16ccddb8667a3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f08d1e2030af4516978d78c5ffb39b75","IPY_MODEL_f33f2b200318432891554fae89824762","IPY_MODEL_c7acf09214d947f78d3a37bc90f063f3"],"layout":"IPY_MODEL_eea375d0ffae45aea50b91e3dbd9ee43"}},"f08d1e2030af4516978d78c5ffb39b75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0234b6b2e8e549d2888d64dc80d0ba19","placeholder":"​","style":"IPY_MODEL_33e665e2feb64edeb851d56b0a9693ad","value":"tokenizer_config.json: 100%"}},"f33f2b200318432891554fae89824762":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb87a066d6f548128daa6c19e75dc229","max":352,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c133545204b4197b79e42b5aad5c593","value":352}},"c7acf09214d947f78d3a37bc90f063f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1cbc87fa4b554f859ee34280deedaa08","placeholder":"​","style":"IPY_MODEL_51f670de832d440e9b701cb02cdd6eac","value":" 352/352 [00:00&lt;00:00, 28.7kB/s]"}},"eea375d0ffae45aea50b91e3dbd9ee43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0234b6b2e8e549d2888d64dc80d0ba19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33e665e2feb64edeb851d56b0a9693ad":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb87a066d6f548128daa6c19e75dc229":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c133545204b4197b79e42b5aad5c593":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1cbc87fa4b554f859ee34280deedaa08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51f670de832d440e9b701cb02cdd6eac":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"910a619f7ce9433b93ff887c4eae93f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52744d6d61f9454fa9a86f2963b752dc","IPY_MODEL_451d29ca2679474e90aa08d5dcca294f","IPY_MODEL_d41ab5e05360451799b1c3e5ce75c885"],"layout":"IPY_MODEL_e06aaeaa78194435983595b3761ec32c"}},"52744d6d61f9454fa9a86f2963b752dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_44a9c2af273847bfbbbf4a51983eabdc","placeholder":"​","style":"IPY_MODEL_8368476b389c40d884d4d27a02e4e943","value":"vocab.txt: 100%"}},"451d29ca2679474e90aa08d5dcca294f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_02112283cdc44eaab75e502fb02145fd","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0888ca81d8c8461592cac1cdb79c0068","value":231508}},"d41ab5e05360451799b1c3e5ce75c885":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ca013dbc146417baf19a58c869c58ad","placeholder":"​","style":"IPY_MODEL_0c0bd5fffb4c484191b77dcf0946367f","value":" 232k/232k [00:00&lt;00:00, 3.39MB/s]"}},"e06aaeaa78194435983595b3761ec32c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"44a9c2af273847bfbbbf4a51983eabdc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8368476b389c40d884d4d27a02e4e943":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"02112283cdc44eaab75e502fb02145fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0888ca81d8c8461592cac1cdb79c0068":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ca013dbc146417baf19a58c869c58ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c0bd5fffb4c484191b77dcf0946367f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fa312a7826bd4177b6f29b3e546f1f5e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_618f41780eac44f89af3c6d69259da7c","IPY_MODEL_84c0d4011bf5445886e028148286cd65","IPY_MODEL_98ef057a8593467ab5ac47d42a962c20"],"layout":"IPY_MODEL_55aca91a721143f2a812cb075281691c"}},"618f41780eac44f89af3c6d69259da7c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af41ed3bcd6a4b1daefd0e13af7a29c8","placeholder":"​","style":"IPY_MODEL_b34edaccd9c84558b802b05453d4feb7","value":"tokenizer.json: 100%"}},"84c0d4011bf5445886e028148286cd65":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_562157ce6a9d466f9dad74744f5b21e9","max":466247,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be71680502884e058cc422c0944b71e1","value":466247}},"98ef057a8593467ab5ac47d42a962c20":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d07f36784f5e4dcfb7a73aa94b86ba55","placeholder":"​","style":"IPY_MODEL_766f08533b9d45e29af10cc834a45e8e","value":" 466k/466k [00:00&lt;00:00, 6.14MB/s]"}},"55aca91a721143f2a812cb075281691c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af41ed3bcd6a4b1daefd0e13af7a29c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b34edaccd9c84558b802b05453d4feb7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"562157ce6a9d466f9dad74744f5b21e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be71680502884e058cc422c0944b71e1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d07f36784f5e4dcfb7a73aa94b86ba55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"766f08533b9d45e29af10cc834a45e8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e032417d203245fe95d72598fb364ae7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7eb250a1f294cff856d73ae79979bcc","IPY_MODEL_8b304b474c994703a60fbb5494fc1874","IPY_MODEL_b8be33e15ebe461d936a20340cc21fc3"],"layout":"IPY_MODEL_8f5376faa05e49778fe82ef7b52c25e0"}},"e7eb250a1f294cff856d73ae79979bcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7196c323255c47adb5f36af7d36f1352","placeholder":"​","style":"IPY_MODEL_cbd097cf678c417fa1d6fcca1f7b193a","value":"special_tokens_map.json: 100%"}},"8b304b474c994703a60fbb5494fc1874":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e17f3f58c6a548be87da670a1b5f0416","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a199c61fef7464b9c28b475e831b7aa","value":112}},"b8be33e15ebe461d936a20340cc21fc3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c90ec151b70445d48a57c34c04be9046","placeholder":"​","style":"IPY_MODEL_a5359c42601240fc80a83d2728347268","value":" 112/112 [00:00&lt;00:00, 10.5kB/s]"}},"8f5376faa05e49778fe82ef7b52c25e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7196c323255c47adb5f36af7d36f1352":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbd097cf678c417fa1d6fcca1f7b193a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e17f3f58c6a548be87da670a1b5f0416":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a199c61fef7464b9c28b475e831b7aa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c90ec151b70445d48a57c34c04be9046":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a5359c42601240fc80a83d2728347268":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b408784d57b64d25b9d3a75b10454850":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_471a321aca9f47b2bfb3a3f26ca974b5","IPY_MODEL_632a9be231c84a519f50363c3a453aa5","IPY_MODEL_660a72738dd74a2b8b62e367a94a445c"],"layout":"IPY_MODEL_a14d0c53791c4838bd51f442fbd0381d"}},"471a321aca9f47b2bfb3a3f26ca974b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ce8913510d64fae8c63b80a705ee23a","placeholder":"​","style":"IPY_MODEL_a8465dad544b459ba0cab1ef037f6389","value":"config.json: 100%"}},"632a9be231c84a519f50363c3a453aa5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9b1034ce65d74b4f8e42f86036ae926d","max":190,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7fc026d0d502438384518b84fbe7d0b2","value":190}},"660a72738dd74a2b8b62e367a94a445c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a7d877dc5c948ec81825e731bf6722e","placeholder":"​","style":"IPY_MODEL_f5b9e80797cd4b5f934303f92ed17bc6","value":" 190/190 [00:00&lt;00:00, 15.4kB/s]"}},"a14d0c53791c4838bd51f442fbd0381d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ce8913510d64fae8c63b80a705ee23a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a8465dad544b459ba0cab1ef037f6389":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9b1034ce65d74b4f8e42f86036ae926d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7fc026d0d502438384518b84fbe7d0b2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3a7d877dc5c948ec81825e731bf6722e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5b9e80797cd4b5f934303f92ed17bc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOqKyGhBPz8X","executionInfo":{"status":"ok","timestamp":1746483609241,"user_tz":300,"elapsed":16043,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"aab0b016-1160-41e0-f724-2b6be97fbe5c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["os.chdir(\"/content/drive/My Drive/School/CS5322 - NLP/Program 3\")"],"metadata":{"id":"QYr3024GP6fM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["os.listdir()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n_BHPPGdWKuH","executionInfo":{"status":"ok","timestamp":1746483610899,"user_tz":300,"elapsed":283,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"417cf8e7-f8db-43d3-eb30-7ee9d7d4307b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['result_sample_conviction_test.txt',\n"," 'sample_conviction_test.txt',\n"," '5322s25prog3.pdf',\n"," 'cs5322s25.py',\n"," 'camper_test.txt',\n"," 'result_camper_test.txt',\n"," 'conviction_test.txt',\n"," 'result_conviction_test.txt',\n"," 'deed_test.txt',\n"," 'result_deed_test.txt',\n"," 'NLP_Program_3.html',\n"," 'conviction_clf.joblib',\n"," 'conviction_vec.joblib',\n"," 'result_deed_YourName.txt',\n"," 'result_conviction_YourName.txt',\n"," 'result_camper_YourName.txt',\n"," 'conviction_pipe.joblib',\n"," 'camper_pipe.joblib',\n"," 'deed_pipe.joblib',\n"," 'conviction_ensemble_pipe.joblib',\n"," 'camper_ensemble_pipe.joblib',\n"," 'deed_ensemble_pipe.joblib',\n"," 'conviction_stack_pipe.joblib',\n"," 'camper_stack_pipe.joblib',\n"," 'deed_stack_pipe_augmented.joblib',\n"," 'camper_stack_pipe_augmented.joblib',\n"," 'conviction_stack_pipe_augmented.joblib',\n"," 'camper_mlp_sbert.joblib',\n"," 'deed_mlp_sbert.joblib',\n"," 'prog3.zip',\n"," 'camper_new_test.txt',\n"," 'result_camper_new_test.txt',\n"," 'conviction_new_test.txt',\n"," 'result_conviction_new_test.txt',\n"," 'deed_new_test.txt',\n"," 'result_deed_new_test.txt',\n"," 'camper_mlp_sbert_tuned.joblib',\n"," 'camper_newer_test.txt',\n"," 'result_camper_newer_test.txt',\n"," 'conviction_newer_test.txt',\n"," 'result_conviction_newer_test.txt',\n"," 'deed_newer_test.txt',\n"," 'result_deed_newer_test.txt',\n"," 'conviction_hard_test.txt',\n"," 'result_conviction_hard_test.txt',\n"," 'conviction_mlp_sbert.joblib',\n"," 'camper_mlp_sbert_aug.joblib',\n"," 'deed_stack_pipe.joblib',\n"," 'conviction_mlp.joblib',\n"," 'conviction_stack.joblib',\n"," 'camper_mlp.joblib',\n"," 'camper_stack.joblib',\n"," 'deed_mlp.joblib',\n"," 'deed_stack.joblib',\n"," 'conviction_ensemble.joblib',\n"," 'camper_ensemble.joblib',\n"," 'deed_ensemble.joblib',\n"," 'NLP_Program_3.ipynb',\n"," 'conviction.txt',\n"," 'deed.txt',\n"," 'camper.txt']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["#!jupyter nbconvert --to html NLP_Program_3.ipynb"],"metadata":{"id":"4mJXcamfV35Z"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8vpXzAksPkfa"},"outputs":[],"source":["def load_data(path):\n","    \"\"\"\n","    Reads a file where each line is:\n","       <sense> <sentence>\n","    Skips headers, blank lines, and definition lines.\n","    Returns: (sentences, labels)\n","    \"\"\"\n","    sentences, labels = [], []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            line = line.strip()\n","            if not line:\n","                continue\n","            # split into at most two parts\n","            parts = line.split(None, 1)\n","            if len(parts) != 2:\n","                continue\n","            sense, text = parts\n","            # only accept exactly '1' or '2'\n","            if sense not in (\"1\", \"2\"):\n","                continue\n","            sentences.append(text)\n","            labels.append(int(sense))\n","    return sentences, labels\n"]},{"cell_type":"code","source":["# Example:\n","train_sents, train_labels = load_data(\"conviction.txt\")\n","print(f\"Loaded {len(train_sents)} examples (sense 1: {train_labels.count(1)}, sense 2: {train_labels.count(2)})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pXxnCKOuQf9V","executionInfo":{"status":"ok","timestamp":1746418516449,"user_tz":300,"elapsed":5,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"3375c657-a602-4bb4-9544-b4430c110532"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 40 examples (sense 1: 20, sense 2: 20)\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer(\n","    lowercase=True,\n","    token_pattern=r\"\\b\\w+\\b\",\n","    ngram_range=(1,3),\n","    min_df=1,\n",")\n","\n","\n","X_train = vectorizer.fit_transform(train_sents)\n"],"metadata":{"id":"FIOzbKNaQHdQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.naive_bayes import MultinomialNB\n","\n","clf = MultinomialNB()\n","clf.fit(X_train, train_labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":80},"id":"MOnwnIhCQK6d","executionInfo":{"status":"ok","timestamp":1746418516488,"user_tz":300,"elapsed":17,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"3d7a1310-de11-424d-d1a4-92cdc2cd7915"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MultinomialNB()"],"text/html":["<style>#sk-container-id-3 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: #000;\n","  --sklearn-color-text-muted: #666;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-3 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-3 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-3 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-3 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-3 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-3 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-3 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-3 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-3 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-3 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-3 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-3 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: flex;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","  align-items: start;\n","  justify-content: space-between;\n","  gap: 0.5em;\n","}\n","\n","#sk-container-id-3 label.sk-toggleable__label .caption {\n","  font-size: 0.6rem;\n","  font-weight: lighter;\n","  color: var(--sklearn-color-text-muted);\n","}\n","\n","#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-3 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-3 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-3 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-3 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-3 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-3 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-3 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 0.5em;\n","  text-align: center;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-3 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-3 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-3 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["def load_test_sentences(path):\n","    \"\"\"\n","    Reads a file where each line is just a sentence (no sense label).\n","    Returns a list of those sentences.\n","    \"\"\"\n","    sentences = []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            text = line.strip()\n","            if text:\n","                sentences.append(text)\n","    return sentences\n"],"metadata":{"id":"z-FnNaAHREaV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ---- training remains the same ----\n","train_sents, train_labels = load_data(\"conviction.txt\")\n","vectorizer.fit(train_sents)\n","clf.fit(vectorizer.transform(train_sents), train_labels)\n","\n","# ---- for your sample test ----\n","test_sents = load_test_sentences(\"sample_conviction_test.txt\")\n","X_test    = vectorizer.transform(test_sents)\n","preds     = clf.predict(X_test)\n","\n","# load gold labels as before\n","with open(\"result_sample_conviction_test.txt\") as f:\n","    gold = [int(line.strip()) for line in f if line.strip()]\n","\n","print(\"Predictions:\", preds.tolist())\n","print(\"Gold      :\", gold)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zu2hM9dtQ5aR","executionInfo":{"status":"ok","timestamp":1746418516547,"user_tz":300,"elapsed":57,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"9d746941-92a7-4f6b-8c1c-1967952a0721"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions: [2, 2, 1, 2]\n","Gold      : [2, 2, 1, 2]\n"]}]},{"cell_type":"code","source":["probs = clf.predict_proba(X_test)\n","for sent, pred, p in zip(test_sents, preds, probs):\n","    print(f\"Sentence: {sent!r}\")\n","    print(f\"  → Predicted sense: {pred}  (p₁={p[0]:.2f}, p₂={p[1]:.2f})\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rZc8CM2GRWM0","executionInfo":{"status":"ok","timestamp":1746418516548,"user_tz":300,"elapsed":7,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"43a6d383-c237-46c0-ecf4-5841b20d2c17"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: 'His bloody palm print on the bat eventually led to his conviction.'\n","  → Predicted sense: 2  (p₁=0.39, p₂=0.61)\n","\n","Sentence: 'A Sioux City woman found guilty of over 50 voter fraud charges is seeking to appeal her conviction.'\n","  → Predicted sense: 2  (p₁=0.42, p₂=0.58)\n","\n","Sentence: 'He spoke with conviction and sincerity.'\n","  → Predicted sense: 1  (p₁=0.51, p₂=0.49)\n","\n","Sentence: 'What are the grounds for appealing a conviction?'\n","  → Predicted sense: 2  (p₁=0.47, p₂=0.53)\n","\n"]}]},{"cell_type":"code","source":["import joblib   # for saving/loading\n","\n","# after training, save both vectorizer & classifier:\n","joblib.dump(vectorizer, \"conviction_vec.joblib\")\n","joblib.dump(clf,          \"conviction_clf.joblib\")\n","\n","def WSD_Test_conviction(sentences):\n","    \"\"\"\n","    sentences: list[str]\n","    returns:   list[int] (1 or 2)\n","    \"\"\"\n","    vec = joblib.load(\"conviction_vec.joblib\")\n","    model = joblib.load(\"conviction_clf.joblib\")\n","    X   = vec.transform(sentences)\n","    return model.predict(X).tolist()\n"],"metadata":{"id":"t8RWqq1dQUfw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import spacy\n","from sklearn.base import TransformerMixin\n","from sklearn.pipeline import Pipeline\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import LinearSVC\n","from sklearn.model_selection import cross_val_score\n","import joblib\n","\n","# 1. Lemmatizer transformer\n","nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\",\"ner\"])\n","class LemmaTransformer(TransformerMixin):\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        out = []\n","        for doc in nlp.pipe(X, batch_size=50):\n","            lemmas = [tok.lemma_ for tok in doc if tok.is_alpha]\n","            out.append(\" \".join(lemmas))\n","        return out\n","\n","# 2. Build the pipeline\n","pipe = Pipeline([\n","    (\"lemma\", LemmaTransformer()),\n","    (\"tfidf\", TfidfVectorizer(ngram_range=(1,3), min_df=1, token_pattern=r\"\\b\\w+\\b\")),\n","    (\"clf\",  LinearSVC(max_iter=5000)),\n","])\n","\n","# 3. Load conviction training data\n","train_sents, train_labels = load_data(\"conviction.txt\")\n","\n","# 4. 5-fold cross-validation\n","cv_scores = cross_val_score(pipe, train_sents, train_labels, cv=5)\n","print(\"Conviction CV scores:\", cv_scores)\n","print(\" mean accuracy: %.3f\" % cv_scores.mean())\n","\n","# 5. Fit on full conviction set & save\n","pipe.fit(train_sents, train_labels)\n","joblib.dump(pipe, \"conviction_pipe.joblib\")\n","\n","# 6. Rerun sample test\n","def load_test(path):\n","    return [line.strip() for line in open(path, encoding=\"utf-8\") if line.strip()]\n","\n","test_sents = load_test(\"sample_conviction_test.txt\")\n","preds = pipe.predict(test_sents)\n","print(\"New Predictions:\", preds.tolist())\n","\n","gold = [int(line.strip()) for line in open(\"result_sample_conviction_test.txt\") if line.strip()]\n","print(\" Gold labels   :\", gold)\n","print(\"Accuracy:\", (preds == gold).mean())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2JPHd6NSSNO","executionInfo":{"status":"ok","timestamp":1746418518669,"user_tz":300,"elapsed":2079,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"d0f1db83-517d-4614-fd1f-4b0164ca98b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Conviction CV scores: [0.75  1.    0.875 0.625 0.875]\n"," mean accuracy: 0.825\n","New Predictions: [2, 2, 1, 2]\n"," Gold labels   : [2, 2, 1, 2]\n","Accuracy: 1.0\n"]}]},{"cell_type":"code","source":["import joblib\n","from sklearn.pipeline import Pipeline\n","from sklearn.svm import LinearSVC\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import cross_val_score\n","\n","# (Reuse your LemmaTransformer and load_data from before)\n","\n","def train_and_save(word):\n","    # 1) Load data\n","    sents, labels = load_data(f\"{word}.txt\")\n","\n","    # 2) Build pipeline\n","    pipe = Pipeline([\n","        (\"lemma\", LemmaTransformer()),\n","        (\"tfidf\", TfidfVectorizer(ngram_range=(1,3), min_df=1, token_pattern=r\"\\b\\w+\\b\")),\n","        (\"clf\",  LinearSVC(max_iter=5000)),\n","    ])\n","\n","    # 3) Cross-validate\n","    scores = cross_val_score(pipe, sents, labels, cv=5)\n","    print(f\"{word:>10} CV scores: {scores} | mean={scores.mean():.3f}\")\n","\n","    # 4) Retrain on full data & save\n","    pipe.fit(sents, labels)\n","    joblib.dump(pipe, f\"{word}_pipe.joblib\")\n","    print(f\"→ Saved {word}_pipe.joblib\\n\")\n","\n","# Run for each target word\n","for w in [\"conviction\", \"camper\", \"deed\"]:\n","    train_and_save(w)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2UA_UcOSnXB","executionInfo":{"status":"ok","timestamp":1746418521103,"user_tz":300,"elapsed":2435,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"58e7a29d-e324-46a3-996d-d3d87957d995"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["conviction CV scores: [0.75  1.    0.875 0.625 0.875] | mean=0.825\n","→ Saved conviction_pipe.joblib\n","\n","    camper CV scores: [0.63636364 0.72727273 0.6        0.8        0.9       ] | mean=0.733\n","→ Saved camper_pipe.joblib\n","\n","      deed CV scores: [0.875 0.625 0.875 0.625 0.625] | mean=0.725\n","→ Saved deed_pipe.joblib\n","\n"]}]},{"cell_type":"code","source":["import joblib\n","\n","def WSD_Test_camper(sentences):\n","    return joblib.load(\"camper_pipe.joblib\").predict(sentences).tolist()\n","\n","def WSD_Test_conviction(sentences):\n","    return joblib.load(\"conviction_pipe.joblib\").predict(sentences).tolist()\n","\n","def WSD_Test_deed(sentences):\n","    return joblib.load(\"deed_pipe.joblib\").predict(sentences).tolist()\n"],"metadata":{"id":"QYZ0eZrgStud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def load_test(path):\n","    return [line.strip() for line in open(path, encoding=\"utf-8\") if line.strip()]\n","\n","for w in [\"camper\",\"conviction\",\"deed\"]:\n","    sents = load_test(f\"{w}_test.txt\")\n","    preds = globals()[f\"WSD_Test_{w}\"](sents)\n","    with open(f\"result_{w}_YourName.txt\",\"w\") as out:\n","        out.write(\"\\n\".join(map(str, preds)))\n"],"metadata":{"id":"FaltMZhAS-LI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ensure you’ve already defined load_data (the sense-aware loader from before)\n","# and that LemmaTransformer etc. are importable in this notebook.\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report\n","import joblib\n","\n","words = [\"conviction\", \"camper\", \"deed\"]\n","\n","for word in words:\n","    # 1) Load the full labeled data\n","    sents, labels = load_data(f\"{word}.txt\")\n","\n","    # 2) Split off an unseen test set (30% of the examples)\n","    X_train, X_test, y_train, y_test = train_test_split(\n","        sents, labels,\n","        test_size=0.30,\n","        stratify=labels,\n","        random_state=42\n","    )\n","\n","    # 3) Load your saved pipeline\n","    pipe = joblib.load(f\"{word}_pipe.joblib\")\n","\n","    # 4) Predict on the hold-out\n","    preds = pipe.predict(X_test)\n","\n","    # 5) Report\n","    print(f\"\\n=== {word.upper()} ===\")\n","    print(f\" Test size: {len(X_test)} sentences\")\n","    print(\" Accuracy :\", accuracy_score(y_test, preds))\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, preds, digits=3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKh7AxV2TY9F","executionInfo":{"status":"ok","timestamp":1746418521386,"user_tz":300,"elapsed":117,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"105425be-03dd-4fb0-f7b0-1e85b35624b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== CONVICTION ===\n"," Test size: 12 sentences\n"," Accuracy : 1.0\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         6\n","           2      1.000     1.000     1.000         6\n","\n","    accuracy                          1.000        12\n","   macro avg      1.000     1.000     1.000        12\n","weighted avg      1.000     1.000     1.000        12\n","\n","\n","=== CAMPER ===\n"," Test size: 16 sentences\n"," Accuracy : 1.0\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         8\n","           2      1.000     1.000     1.000         8\n","\n","    accuracy                          1.000        16\n","   macro avg      1.000     1.000     1.000        16\n","weighted avg      1.000     1.000     1.000        16\n","\n","\n","=== DEED ===\n"," Test size: 12 sentences\n"," Accuracy : 1.0\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         6\n","           2      1.000     1.000     1.000         6\n","\n","    accuracy                          1.000        12\n","   macro avg      1.000     1.000     1.000        12\n","weighted avg      1.000     1.000     1.000        12\n","\n"]}]},{"cell_type":"code","source":["for w in [\"camper\",\"conviction\",\"deed\"]:\n","    sents = load_test(f\"{w}_test.txt\")\n","    preds = globals()[f\"WSD_Test_{w}\"](sents)\n","    print(w, \"accuracy:\", sum(int(p)==g for p,g in zip(preds, open(f\"result_{w}_test.txt\"))) / len(preds))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U66YXGyKUj4N","executionInfo":{"status":"ok","timestamp":1746418521534,"user_tz":300,"elapsed":145,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"098d9ec6-c673-49b6-f224-361a2f9507bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["camper accuracy: 0.0\n","conviction accuracy: 0.0\n","deed accuracy: 0.0\n"]}]},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.svm import LinearSVC\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import cross_val_score\n","import joblib\n","\n","def train_and_save(word):\n","    # 1) load the sense‐labeled data\n","    sents, labels = load_data(f\"{word}.txt\")\n","\n","    # 2) build the exact same pipeline you used for conviction\n","    pipe = Pipeline([\n","        (\"lemma\" , LemmaTransformer()),\n","        (\"tfidf\" , TfidfVectorizer(ngram_range=(1,3), min_df=1, token_pattern=r\"\\b\\w+\\b\")),\n","        (\"clf\"   , LinearSVC(max_iter=5000)),\n","    ])\n","\n","    # 3) quick CV check\n","    scores = cross_val_score(pipe, sents, labels, cv=5)\n","    print(f\"{word:>10} CV acc: {scores.mean():.3f}  →  {scores}\")\n","\n","    # 4) retrain on full data & save\n","    pipe.fit(sents, labels)\n","    joblib.dump(pipe, f\"{word}_pipe.joblib\")\n","    print(f\"Saved pipeline to {word}_pipe.joblib\\n\")\n","\n","# Train all three\n","for w in [\"conviction\",\"camper\",\"deed\"]:\n","    train_and_save(w)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RSEdHD7TVGmO","executionInfo":{"status":"ok","timestamp":1746418523135,"user_tz":300,"elapsed":1632,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"cdc4ed77-bdf9-433e-c557-1c9eb7f8f946"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["conviction CV acc: 0.825  →  [0.75  1.    0.875 0.625 0.875]\n","Saved pipeline to conviction_pipe.joblib\n","\n","    camper CV acc: 0.733  →  [0.63636364 0.72727273 0.6        0.8        0.9       ]\n","Saved pipeline to camper_pipe.joblib\n","\n","      deed CV acc: 0.725  →  [0.875 0.625 0.875 0.625 0.625]\n","Saved pipeline to deed_pipe.joblib\n","\n"]}]},{"cell_type":"code","source":["def load_gold(path):\n","    labels = []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            tok = line.strip()\n","            # only accept lines that are exactly “1” or “2”\n","            if tok in (\"1\",\"2\"):\n","                labels.append(int(tok))\n","    return labels\n","\n","# then in your loop:\n","gold = load_gold(f\"result_{word}_test.txt\")\n"],"metadata":{"id":"jAEyBUUxVa9V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import LinearSVC\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","pipe = Pipeline([\n","    (\"lemma\" , LemmaTransformer()),               # spaCy lemmatizer\n","    (\"tfidf\" , TfidfVectorizer(token_pattern=r\"\\b\\w+\\b\")),\n","    (\"clf\"   , LinearSVC()),\n","])\n","\n","param_grid = {\n","    \"tfidf__ngram_range\": [(1,2), (1,3), (2,3)],\n","    \"tfidf__min_df\": [1,2],\n","    \"clf__C\": [0.1, 1, 10],\n","}\n","\n","search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=1, scoring=\"accuracy\")\n","search.fit(train_sents, train_labels)\n","\n","print(\"Best params:\", search.best_params_)\n","print(\"Best CV:\", search.best_score_)\n","best_pipe = search.best_estimator_\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xD-MctidVNBZ","executionInfo":{"status":"ok","timestamp":1746418531164,"user_tz":300,"elapsed":8026,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"1bb237c5-6340-4976-8f1f-d644f06d8f41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best params: {'clf__C': 0.1, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 3)}\n","Best CV: 0.825\n"]}]},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.svm import LinearSVC\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import GridSearchCV\n","import joblib\n","\n","# reuse your LemmaTransformer, param_grid, and pipe template\n","for word in [\"conviction\", \"camper\", \"deed\"]:\n","    sents, labels = load_data(f\"{word}.txt\")\n","    pipe = Pipeline([\n","        (\"lemma\", LemmaTransformer()),\n","        (\"tfidf\", TfidfVectorizer(token_pattern=r\"\\b\\w+\\b\")),\n","        (\"clf\"  , LinearSVC()),\n","    ])\n","    search = GridSearchCV(pipe, param_grid, cv=5, n_jobs=1, scoring=\"accuracy\")\n","    search.fit(sents, labels)\n","    print(f\"{word.upper()} best params: {search.best_params_}, CV: {search.best_score_:.3f}\")\n","    joblib.dump(search.best_estimator_, f\"{word}_pipe.joblib\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7G1eTDCHbCh5","executionInfo":{"status":"ok","timestamp":1746418556676,"user_tz":300,"elapsed":25513,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"d59dc12d-09cb-4981-9a4b-47f4b872ce3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CONVICTION best params: {'clf__C': 0.1, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 3)}, CV: 0.825\n","CAMPER best params: {'clf__C': 1, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 3)}, CV: 0.733\n","DEED best params: {'clf__C': 0.1, 'tfidf__min_df': 1, 'tfidf__ngram_range': (2, 3)}, CV: 0.775\n"]}]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import ComplementNB\n","from sklearn.ensemble import RandomForestClassifier\n","\n","extended_param_grid = {\n","    # TF–IDF variants\n","    \"tfidf__analyzer\":       [\"word\", \"char_wb\"],\n","    \"tfidf__ngram_range\":    [(1,2), (1,3), (2,3), (3,5)],\n","    \"tfidf__min_df\":         [1,2],\n","    # Classifier choices\n","    \"clf\": [\n","      LinearSVC(),\n","      LogisticRegression(max_iter=5000),\n","      ComplementNB(),\n","      RandomForestClassifier(n_estimators=100)\n","    ],\n","    # If you pick a classifier with C\n","    \"clf__C\": [0.1, 1, 10],         # will be ignored by NB/RF\n","}\n"],"metadata":{"id":"kzJFpKSccXCM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.naive_bayes import ComplementNB\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","pipe = Pipeline([\n","    (\"lemma\", LemmaTransformer()),\n","    (\"tfidf\", TfidfVectorizer()),      # configure analyzer, ngram_range, etc.\n","    (\"clf\",   LinearSVC()),             # placeholder — will be overridden by GridSearch\n","])\n","\n","param_grids = [\n","    # 1) LinearSVC grid\n","    {\n","      \"tfidf__analyzer\":       [\"word\", \"char_wb\"],\n","      \"tfidf__ngram_range\":    [(1,2), (1,3), (2,3)],\n","      \"tfidf__min_df\":         [1,2],\n","      \"clf\":                   [LinearSVC()],\n","      \"clf__C\":                [0.1, 1, 10],\n","    },\n","    # 2) LogisticRegression grid\n","    {\n","      \"tfidf__analyzer\":       [\"word\", \"char_wb\"],\n","      \"tfidf__ngram_range\":    [(1,2), (1,3), (2,3)],\n","      \"tfidf__min_df\":         [1,2],\n","      \"clf\":                   [LogisticRegression(max_iter=5000)],\n","      \"clf__C\":                [0.1, 1, 10],\n","    },\n","    # 3) ComplementNB grid\n","    {\n","      \"tfidf__analyzer\":       [\"word\", \"char_wb\"],\n","      \"tfidf__ngram_range\":    [(1,2), (1,3), (2,3)],\n","      \"tfidf__min_df\":         [1,2],\n","      \"clf\":                   [ComplementNB()],\n","      \"clf__alpha\":            [0.1, 1, 10],\n","    },\n","    # 4) RandomForest grid\n","    {\n","      \"tfidf__analyzer\":       [\"word\", \"char_wb\"],\n","      \"tfidf__ngram_range\":    [(1,2), (1,3), (2,3)],\n","      \"tfidf__min_df\":         [1,2],\n","      \"clf\":                   [RandomForestClassifier()],\n","      \"clf__n_estimators\":     [100, 200],\n","    },\n","]\n","\n","search = GridSearchCV(\n","    pipe,\n","    param_grids,    # notice: a *list* of dicts, not a single dict\n","    cv=5,\n","    n_jobs=1,       # or pre-lemmatize to safely use n_jobs=-1\n","    scoring=\"accuracy\"\n",")\n","search.fit(train_sents, train_labels)\n","\n","print(\"Best params:\", search.best_params_)\n","print(\"Best CV   :\", search.best_score_)\n","best_pipe = search.best_estimator_\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U6VgUEFteV9_","executionInfo":{"status":"ok","timestamp":1746418662922,"user_tz":300,"elapsed":106244,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"95e872bd-3cb1-4951-aef3-fcc62b31c389"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best params: {'clf': LinearSVC(), 'clf__C': 10, 'tfidf__analyzer': 'word', 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 3)}\n","Best CV   : 0.85\n"]}]},{"cell_type":"code","source":["import joblib\n","\n","for word in [\"conviction\",\"camper\",\"deed\"]:\n","    # 1) load the appropriate training data\n","    sents, labels = load_data(f\"{word}.txt\")\n","\n","    # 2) attach it to the same pipeline & param_grids\n","    search = GridSearchCV(\n","        pipe,\n","        param_grids,    # list of dicts, as we defined\n","        cv=5,\n","        n_jobs=1,       # or -1 if you pre‐lemmatize\n","        scoring=\"accuracy\"\n","    )\n","\n","    # 3) fit & report\n","    search.fit(sents, labels)\n","    print(f\"\\n=== {word.upper()} ===\")\n","    print(\" Best params:\", search.best_params_)\n","    print(\" Best CV   :\", search.best_score_)\n","\n","    # 4) save the tuned pipeline\n","    joblib.dump(search.best_estimator_, f\"{word}_pipe.joblib\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LqdZw6eVfzEE","executionInfo":{"status":"ok","timestamp":1746419028298,"user_tz":300,"elapsed":314066,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"38a2ba46-0974-4709-b2a4-8c3a143a8d07"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== CONVICTION ===\n"," Best params: {'clf': LinearSVC(), 'clf__C': 10, 'tfidf__analyzer': 'word', 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 3)}\n"," Best CV   : 0.85\n","\n","=== CAMPER ===\n"," Best params: {'clf': ComplementNB(), 'clf__alpha': 0.1, 'tfidf__analyzer': 'char_wb', 'tfidf__min_df': 1, 'tfidf__ngram_range': (2, 3)}\n"," Best CV   : 0.809090909090909\n","\n","=== DEED ===\n"," Best params: {'clf': RandomForestClassifier(), 'clf__n_estimators': 100, 'tfidf__analyzer': 'word', 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 3)}\n"," Best CV   : 0.775\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download(\"wordnet\")\n","nltk.download(\"omw-1.4\")\n","\n","\n","#––– Imports –––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––\n","import re\n","import joblib\n","import numpy as np\n","from sklearn.base import TransformerMixin\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import VotingClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import cross_val_score\n","from sentence_transformers import SentenceTransformer\n","import spacy\n","from nltk.corpus import wordnet as wn\n","\n","#––– Helpers –––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––\n","def load_data(path):\n","    \"\"\"Load sense-labeled <sense> <sentence> files.\"\"\"\n","    sents, labs = [], []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            parts = line.strip().split(None,1)\n","            if len(parts)==2 and parts[0] in (\"1\",\"2\"):\n","                labs.append(int(parts[0]))\n","                sents.append(parts[1])\n","    return sents, labs\n","\n","class LemmaTransformer(TransformerMixin):\n","    \"\"\"SpaCy lemmatizer.\"\"\"\n","    def __init__(self):\n","        self.nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\",\"ner\"])\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        out = []\n","        for doc in self.nlp.pipe(X, batch_size=50):\n","            out.append(\" \".join(tok.lemma_ for tok in doc if tok.is_alpha))\n","        return out\n","\n","class SBERTEmbed(TransformerMixin):\n","    \"\"\"Pre‐compute SBERT sentence embeddings.\"\"\"\n","    def __init__(self, model_name=\"all-MiniLM-L6-v2\"):\n","        self.embedder = SentenceTransformer(model_name)\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        return self.embedder.encode(X, convert_to_numpy=True)\n","\n","class WordNetOverlap(TransformerMixin):\n","    \"\"\"Count overlap with WordNet glosses of the two noun senses.\"\"\"\n","    def __init__(self, word):\n","        syns = wn.synsets(word, pos=wn.NOUN)\n","        self.g1 = set(syns[0].definition().lower().split()) if len(syns)>0 else set()\n","        self.g2 = set(syns[1].definition().lower().split()) if len(syns)>1 else set()\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        feats = []\n","        for sent in X:\n","            ws = set(w.lower() for w in re.findall(r\"\\b\\w+\\b\", sent))\n","            feats.append([len(ws & self.g1), len(ws & self.g2)])\n","        return np.array(feats)\n","\n","#––– Ensemble Training Loop –––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––––\n","words = [\"conviction\",\"camper\",\"deed\"]\n","for word in words:\n","    # 1) Load data\n","    sents, labels = load_data(f\"{word}.txt\")\n","\n","    # 2) Build Pipeline A: Lemma + TF–IDF (word+char) + SVM\n","    pipe_a = Pipeline([\n","        (\"lemma\", LemmaTransformer()),\n","        (\"feats\", FeatureUnion([\n","            (\"tf_w\", TfidfVectorizer(analyzer=\"word\",    ngram_range=(1,3), min_df=1)),\n","            (\"tf_c\", TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=1)),\n","            (\"wnov\", WordNetOverlap(word)),\n","        ])),\n","        (\"clf\" , LinearSVC(C=10, max_iter=5000)),\n","    ])\n","\n","    # 3) Build Pipeline B: SBERT embeddings → LogisticRegression\n","    pipe_b = Pipeline([\n","        (\"embed\", SBERTEmbed()),\n","        (\"clf\"  , LogisticRegression(C=1, max_iter=5000)),\n","    ])\n","\n","    # 4) Ensemble via hard voting\n","    eclf = VotingClassifier(\n","        estimators=[(\"svm\", pipe_a), (\"lr\", pipe_b)],\n","        voting=\"hard\"\n","    )\n","\n","    # 5) Cross‐validate the ensemble\n","    scores = cross_val_score(eclf, sents, labels, cv=5, n_jobs=1)\n","    print(f\"{word.upper():>10} Ensemble CV mean: {scores.mean():.3f} | folds: {scores}\")\n","\n","    # 6) Fit on full data & save\n","    eclf.fit(sents, labels)\n","    joblib.dump(eclf, f\"{word}_ensemble_pipe.joblib\")\n","    print(f\"→ Saved ensemble to {word}_ensemble_pipe.joblib\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BtXryvtqi36v","executionInfo":{"status":"ok","timestamp":1746419124069,"user_tz":300,"elapsed":95775,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"b26a27c7-bfbf-449a-a0ea-cc727edc7afb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["CONVICTION Ensemble CV mean: 0.825 | folds: [0.5   1.    0.75  1.    0.875]\n","→ Saved ensemble to conviction_ensemble_pipe.joblib\n","\n","    CAMPER Ensemble CV mean: 0.751 | folds: [0.72727273 0.72727273 0.7        0.7        0.9       ]\n","→ Saved ensemble to camper_ensemble_pipe.joblib\n","\n","      DEED Ensemble CV mean: 0.700 | folds: [0.75  0.625 0.875 0.625 0.625]\n","→ Saved ensemble to deed_ensemble_pipe.joblib\n","\n"]}]},{"cell_type":"code","source":["from nltk import download\n","from nltk.corpus import wordnet as wn\n","download(\"wordnet\"); download(\"omw-1.4\")\n","\n","class WordNetOverlap(TransformerMixin):\n","    def __init__(self, word):\n","        syns = wn.synsets(word, pos=wn.NOUN)\n","        self.g1 = set(syns[0].definition().lower().split()) if syns else set()\n","        self.g2 = set(syns[1].definition().lower().split()) if len(syns)>1 else set()\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        feats = []\n","        for sent in X:\n","            ws = set(re.findall(r\"\\b\\w+\\b\", sent.lower()))\n","            feats.append([len(ws & self.g1), len(ws & self.g2)])\n","        return np.array(feats)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7QmNGx5YquWG","executionInfo":{"status":"ok","timestamp":1746419124081,"user_tz":300,"elapsed":11,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"f2b3d159-3cb5-4b5d-b022-e1a319e5b224"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]}]},{"cell_type":"code","source":["class WindowFeatures(TransformerMixin):\n","    def __init__(self, target):\n","        self.target = target.lower()\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        feat_list = []\n","        for sent in X:\n","            toks = re.findall(r\"\\b\\w+\\b\", sent.lower())\n","            if self.target in toks:\n","                i = toks.index(self.target)\n","                ctx = toks[max(i-2,0):i] + toks[i+1:i+3]\n","            else:\n","                ctx = []\n","            # Example vocabulary—tune on training data\n","            vocab = [\"camp\", \"park\", \"kitchen\", \"drive\", \"lake\", \"bus\",\n","                     \"good\", \"volunteer\", \"property\", \"trust\", \"closing\"]\n","            feat_list.append([int(v in ctx) for v in vocab])\n","        return np.array(feat_list)\n"],"metadata":{"id":"N7SuLq01qwHe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ─── Imports & Downloads ───────────────────────────────────────────────────────────────\n","import re\n","import joblib\n","import numpy as np\n","import nltk\n","nltk.download(\"wordnet\")\n","nltk.download(\"omw-1.4\")\n","from nltk.corpus import wordnet as wn\n","\n","import spacy\n","from sklearn.base import TransformerMixin\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.svm import LinearSVC\n","from sklearn.naive_bayes import ComplementNB\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import StackingClassifier\n","from sklearn.model_selection import cross_val_score\n","\n","# ─── Data Loader ───────────────────────────────────────────────────────────────────────\n","def load_data(path):\n","    \"\"\"Load sense-labeled files where each line is: <sense> <sentence>.\"\"\"\n","    sents, labs = [], []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            parts = line.strip().split(None, 1)\n","            if len(parts) == 2 and parts[0] in (\"1\",\"2\"):\n","                labs.append(int(parts[0]))\n","                sents.append(parts[1])\n","    return sents, labs\n","\n","# ─── Transformers ─────────────────────────────────────────────────────────────────────\n","class LemmaTransformer(TransformerMixin):\n","    \"\"\"SpaCy lemmatizer.\"\"\"\n","    def __init__(self):\n","        self.nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\",\"ner\"])\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        out = []\n","        for doc in self.nlp.pipe(X, batch_size=50):\n","            out.append(\" \".join(tok.lemma_ for tok in doc if tok.is_alpha))\n","        return out\n","\n","class WordNetOverlap(TransformerMixin):\n","    \"\"\"Counts overlap with the two noun glosses for a target word.\"\"\"\n","    def __init__(self, word):\n","        syns = wn.synsets(word, pos=wn.NOUN)\n","        self.g1 = set(syns[0].definition().lower().split()) if len(syns)>0 else set()\n","        self.g2 = set(syns[1].definition().lower().split()) if len(syns)>1 else set()\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        feats = []\n","        for sent in X:\n","            ws = set(re.findall(r\"\\b\\w+\\b\", sent.lower()))\n","            feats.append([len(ws & self.g1), len(ws & self.g2)])\n","        return np.array(feats)\n","\n","class WindowFeatures(TransformerMixin):\n","    \"\"\"Binary flags for a small context window around the target word.\"\"\"\n","    def __init__(self, target):\n","        self.target = target.lower()\n","        # you can tune this vocabulary based on your training data\n","        self.vocab = [\"camp\",\"park\",\"kitchen\",\"drive\",\"lake\",\"bus\",\n","                      \"good\",\"volunteer\",\"property\",\"trust\",\"closing\"]\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        rows = []\n","        for sent in X:\n","            toks = re.findall(r\"\\b\\w+\\b\", sent.lower())\n","            if self.target in toks:\n","                i = toks.index(self.target)\n","                ctx = toks[max(i-2,0):i] + toks[i+1:i+3]\n","            else:\n","                ctx = []\n","            rows.append([int(v in ctx) for v in self.vocab])\n","        return np.array(rows)\n","\n","# ─── Training & Saving Ensembles ───────────────────────────────────────────────────────\n","for word in [\"conviction\",\"camper\",\"deed\"]:\n","    # 1) load data\n","    sents, labels = load_data(f\"{word}.txt\")\n","\n","    # 2) shared FeatureUnion\n","    union = FeatureUnion([\n","        (\"tf_w\",  TfidfVectorizer(analyzer=\"word\",    ngram_range=(1,3), min_df=1)),\n","        (\"tf_c\",  TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=1)),\n","        (\"wnov\",  WordNetOverlap(word)),\n","        (\"wind\",  WindowFeatures(word)),\n","    ])\n","\n","    # 3) base learner A: SVM\n","    pipe_svm = Pipeline([\n","        (\"lemma\", LemmaTransformer()),\n","        (\"feat\",  union),\n","        (\"clf\",   LinearSVC(C=1, max_iter=5000)),\n","    ])\n","\n","    # 4) base learner B: Complement Naive Bayes\n","    pipe_nb = Pipeline([\n","        (\"lemma\", LemmaTransformer()),\n","        (\"feat\",  union),\n","        (\"clf\",   ComplementNB(alpha=0.1)),\n","    ])\n","\n","    # 5) stacking classifier\n","    stack = StackingClassifier(\n","        estimators=[(\"svm\", pipe_svm), (\"nb\", pipe_nb)],\n","        final_estimator=LogisticRegression(max_iter=5000),\n","        cv=5,\n","        n_jobs=1\n","    )\n","\n","    # 6) cross-validate\n","    scores = cross_val_score(stack, sents, labels, cv=5)\n","    print(f\"{word.upper():>10} stacking CV mean: {scores.mean():.3f} | folds: {scores}\")\n","\n","    # 7) retrain on all data & save\n","    stack.fit(sents, labels)\n","    joblib.dump(stack, f\"{word}_stack_pipe.joblib\")\n","    print(f\"→ Saved ensemble to {word}_stack_pipe.joblib\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wUAuZsBBp301","executionInfo":{"status":"ok","timestamp":1746419626265,"user_tz":300,"elapsed":307718,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"2d0931f2-0fa8-4025-faa3-49bf3dae1f99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["CONVICTION stacking CV mean: 0.875 | folds: [0.75  1.    0.875 0.75  1.   ]\n","→ Saved ensemble to conviction_stack_pipe.joblib\n","\n","    CAMPER stacking CV mean: 0.809 | folds: [0.81818182 0.72727273 0.7        0.9        0.9       ]\n","→ Saved ensemble to camper_stack_pipe.joblib\n","\n","      DEED stacking CV mean: 0.700 | folds: [0.875 0.75  0.75  0.5   0.625]\n","→ Saved ensemble to deed_stack_pipe.joblib\n","\n"]}]},{"cell_type":"code","source":["import nltk\n","\n","# ─── Download needed NLTK resources ───────────────────────────────────────────────\n","nltk.download(\"punkt\")                        # sentence / word tokenizer\n","nltk.download(\"punkt_tab\")\n","nltk.download(\"averaged_perceptron_tagger\")   # POS tagger\n","nltk.download(\"wordnet\")                      # WordNet corpus\n","nltk.download(\"omw-1.4\")                      # WordNet multilingual data\n","nltk.download('averaged_perceptron_tagger_eng')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ijB9P6slwj61","executionInfo":{"status":"ok","timestamp":1746420339672,"user_tz":300,"elapsed":368,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"93a5e9b1-d303-48d0-d8ce-8dabbd2e1a92"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":101}]},{"cell_type":"code","source":["import random\n","from nltk import pos_tag, word_tokenize, punkt\n","from nltk.corpus import wordnet as wn\n","\n","def synonym_augment(sentences, labels, n_aug=2):\n","    \"\"\"Generate n_aug new sentences per original by swapping one noun with a synonym.\"\"\"\n","    new_sents, new_labels = [], []\n","    for sent, lab in zip(sentences, labels):\n","        tokens = word_tokenize(sent)\n","        tagged  = pos_tag(tokens)\n","        nouns   = [i for i,(w,tag) in enumerate(tagged) if tag.startswith(\"NN\")]\n","        if not nouns:\n","            continue\n","        for _ in range(n_aug):\n","            i = random.choice(nouns)\n","            synsets = wn.synsets(tokens[i], pos=wn.NOUN)\n","            # pick a random synonym lemma\n","            lemmas = [l.name().replace(\"_\",\" \") for syn in synsets for l in syn.lemmas() if l.name().lower()!=tokens[i].lower()]\n","            if not lemmas:\n","                continue\n","            new_tok = random.choice(lemmas)\n","            aug = tokens.copy()\n","            aug[i] = new_tok\n","            new_sents.append(\" \".join(aug))\n","            new_labels.append(lab)\n","    return sentences + new_sents, labels + new_labels\n","\n","# Usage before training deed:\n","train_sents, train_labels = load_data(\"deed.txt\")\n","aug_sents, aug_labels = synonym_augment(train_sents, train_labels, n_aug=3)\n","print(\"Original:\", len(train_sents), \"Augmented:\", len(aug_sents))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qy_OYrdSwVnz","executionInfo":{"status":"ok","timestamp":1746420341923,"user_tz":300,"elapsed":202,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"7e5ca37f-4241-489d-a13c-9f357f9ed3a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original: 40 Augmented: 143\n"]}]},{"cell_type":"code","source":["from sklearn.metrics.pairwise import cosine_similarity\n","from sentence_transformers import SentenceTransformer\n","\n","class GlossSimilarity(TransformerMixin):\n","    \"\"\"Encodes the two glosses and returns their cosine sims to each sentence.\"\"\"\n","    def __init__(self, word, model_name=\"all-MiniLM-L6-v2\"):\n","        self.embedder = SentenceTransformer(model_name)\n","        syns = wn.synsets(word, pos=wn.NOUN)[:2]\n","        glosses = [syn.definition() for syn in syns]\n","        self.g_embs = self.embedder.encode(glosses, convert_to_numpy=True)\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        s_embs = self.embedder.encode(X, convert_to_numpy=True)\n","        feats  = []\n","        for emb in s_embs:\n","            sims = cosine_similarity(emb.reshape(1,-1), self.g_embs).flatten().tolist()\n","            feats.append(sims)\n","        return np.array(feats)\n"],"metadata":{"id":"6IbrhIDHwXYM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["union = FeatureUnion([\n","  (\"tf_w\", TfidfVectorizer(analyzer=\"word\", ngram_range=(1,3), min_df=1)),\n","  (\"tf_c\", TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=1)),\n","  (\"wnov\", WordNetOverlap(\"deed\")),\n","  (\"wind\", WindowFeatures(\"deed\")),\n","  (\"glos\", GlossSimilarity(\"deed\")),\n","])\n","pipe_deed = Pipeline([\n","  (\"lemma\", LemmaTransformer()),\n","  (\"feat\" , union),\n","  (\"clf\"  , RandomForestClassifier(n_estimators=200, random_state=42)),\n","])\n","scores = cross_val_score(pipe_deed, aug_sents, aug_labels, cv=5)\n","print(\"Deed w/ gloss & augment CV:\", scores.mean(), scores)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ov8Ftc2lwdli","executionInfo":{"status":"ok","timestamp":1746420370198,"user_tz":300,"elapsed":22321,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"106f843f-4e52-4be0-d73c-0df80ffa7641"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Deed w/ gloss & augment CV: 0.993103448275862 [1.         0.96551724 1.         1.         1.        ]\n"]}]},{"cell_type":"code","source":["# assuming `stack` is your final fitted StackingClassifier for \"deed\"\n","stack.fit(aug_sents, aug_labels)\n","joblib.dump(stack, \"deed_stack_pipe.joblib\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fG1pfAPxxSJc","executionInfo":{"status":"ok","timestamp":1746420473255,"user_tz":300,"elapsed":27974,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"ef82a3c6-3db8-4c9d-bea4-1f9c926b0702"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['deed_stack_pipe.joblib']"]},"metadata":{},"execution_count":105}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sklearn.model_selection import cross_val_score\n","import joblib\n","\n","words = [\"deed\", \"camper\", \"conviction\"]\n","\n","for word in words:\n","    # 1) load and augment\n","    train_sents, train_labels = load_data(f\"{word}.txt\")\n","    aug_sents, aug_labels   = synonym_augment(train_sents, train_labels, n_aug=3)\n","    print(f\"{word.upper():} Original: {len(train_sents)}, Augmented: {len(aug_sents)}\")\n","\n","    # 2) build FeatureUnion for this word\n","    union = FeatureUnion([\n","      (\"tf_w\",  TfidfVectorizer(analyzer=\"word\",    ngram_range=(1,3), min_df=1)),\n","      (\"tf_c\",  TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=1)),\n","      (\"wnov\",  WordNetOverlap(word)),\n","      (\"wind\",  WindowFeatures(word)),\n","      (\"glos\",  GlossSimilarity(word)),\n","    ])\n","\n","    # 3) pipeline\n","    pipe = Pipeline([\n","      (\"lemma\", LemmaTransformer()),\n","      (\"feat\" , union),\n","      (\"clf\"  , RandomForestClassifier(n_estimators=200, random_state=42)),\n","    ])\n","\n","    # 4) CV evaluation\n","    scores = cross_val_score(pipe, aug_sents, aug_labels, cv=5)\n","    print(f\"{word.upper()} w/ gloss & augment CV: {scores.mean():.3f}  folds: {scores}\")\n","\n","    # 5) train on full augmented data & save\n","    pipe.fit(aug_sents, aug_labels)\n","    joblib.dump(pipe, f\"{word}_stack_pipe_augmented.joblib\")\n","    print(f\"→ Saved {word}_stack_pipe_augmented.joblib\\n\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MrXhEXZSyqip","executionInfo":{"status":"ok","timestamp":1746421334583,"user_tz":300,"elapsed":94284,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"76b9d500-6f8a-47cb-8d79-0e441d7a9de3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["DEED Original: 40, Augmented: 153\n","DEED w/ gloss & augment CV: 1.000  folds: [1. 1. 1. 1. 1.]\n","→ Saved deed_stack_pipe_augmented.joblib\n","\n","CAMPER Original: 52, Augmented: 199\n","CAMPER w/ gloss & augment CV: 0.995  folds: [1.    1.    1.    0.975 1.   ]\n","→ Saved camper_stack_pipe_augmented.joblib\n","\n","CONVICTION Original: 40, Augmented: 149\n","CONVICTION w/ gloss & augment CV: 1.000  folds: [1. 1. 1. 1. 1.]\n","→ Saved conviction_stack_pipe_augmented.joblib\n","\n"]}]},{"cell_type":"code","source":["def load_test_sentences(path):\n","    with open(path, encoding=\"utf-8\") as f:\n","        return [\n","            line.strip() for line in f\n","            if line.strip() and not line.lstrip().startswith(\"#\")\n","        ]\n","\n","def load_gold_labels(path):\n","    labs = []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            tok = line.strip()\n","            if tok in (\"1\",\"2\"):           # only accept numeric labels\n","                labs.append(int(tok))\n","    return labs\n","\n","# Quick length‐check\n","for w in [\"camper\",\"conviction\",\"deed\"]:\n","    sents = load_test_sentences(f\"{w}_test.txt\")\n","    gold  = load_gold_labels(    f\"result_{w}_test.txt\")\n","    print(f\"{w}: #sents={len(sents)}, #labels={len(gold)}\")\n","\n","# Then your evaluation:\n","from sklearn.metrics import accuracy_score, classification_report\n","import joblib\n","\n","for w in [\"camper\",\"conviction\",\"deed\"]:\n","    sents = load_test_sentences(f\"{w}_test.txt\")\n","    gold  = load_gold_labels(    f\"result_{w}_test.txt\")\n","    pipe  = joblib.load(f\"{w}_stack_pipe.joblib\")\n","    preds = pipe.predict(sents)\n","    print(f\"\\n=== {w.upper()} TEST ===\")\n","    print(\"Accuracy:\", f\"{accuracy_score(gold,preds):.2%}\")\n","    print(classification_report(gold,preds, digits=3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZhglBvagxpZD","executionInfo":{"status":"ok","timestamp":1746421353706,"user_tz":300,"elapsed":12118,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"ea2a567c-a01c-430b-e7d5-42d6b7d8ec18"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["camper: #sents=10, #labels=10\n","conviction: #sents=10, #labels=10\n","deed: #sents=10, #labels=10\n","\n","=== CAMPER TEST ===\n","Accuracy: 70.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.667     0.800     0.727         5\n","           2      0.750     0.600     0.667         5\n","\n","    accuracy                          0.700        10\n","   macro avg      0.708     0.700     0.697        10\n","weighted avg      0.708     0.700     0.697        10\n","\n","\n","=== CONVICTION TEST ===\n","Accuracy: 70.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.750     0.600     0.667         5\n","           2      0.667     0.800     0.727         5\n","\n","    accuracy                          0.700        10\n","   macro avg      0.708     0.700     0.697        10\n","weighted avg      0.708     0.700     0.697        10\n","\n","\n","=== DEED TEST ===\n","Accuracy: 80.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.714     1.000     0.833         5\n","           2      1.000     0.600     0.750         5\n","\n","    accuracy                          0.800        10\n","   macro avg      0.857     0.800     0.792        10\n","weighted avg      0.857     0.800     0.792        10\n","\n"]}]},{"cell_type":"code","source":["def load_test_sentences(path):\n","    with open(path, encoding=\"utf-8\") as f:\n","        return [\n","            line.strip() for line in f\n","            if line.strip() and not line.lstrip().startswith(\"#\")\n","        ]\n","\n","def load_gold_labels(path):\n","    labs = []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            tok = line.strip()\n","            if tok in (\"1\",\"2\"):           # only accept numeric labels\n","                labs.append(int(tok))\n","    return labs\n","\n","# Quick length‐check\n","for w in [\"camper\",\"conviction\",\"deed\"]:\n","    sents = load_test_sentences(f\"{w}_test.txt\")\n","    gold  = load_gold_labels(    f\"result_{w}_test.txt\")\n","    print(f\"{w}: #sents={len(sents)}, #labels={len(gold)}\")\n","\n","# Then your evaluation:\n","from sklearn.metrics import accuracy_score, classification_report\n","import joblib\n","\n","for w in [\"camper\",\"conviction\",\"deed\"]:\n","    sents = load_test_sentences(f\"{w}_test.txt\")\n","    gold  = load_gold_labels(    f\"result_{w}_test.txt\")\n","    pipe  = joblib.load(f\"{w}_stack_pipe_augmented.joblib\")\n","    preds = pipe.predict(sents)\n","    print(f\"\\n=== {w.upper()} TEST ===\")\n","    print(\"Accuracy:\", f\"{accuracy_score(gold,preds):.2%}\")\n","    print(classification_report(gold,preds, digits=3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fF8UsvEC05ZQ","executionInfo":{"status":"ok","timestamp":1746421412203,"user_tz":300,"elapsed":4949,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"f941f719-a923-4600-ccf3-8248f1a3a3f3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["camper: #sents=10, #labels=10\n","conviction: #sents=10, #labels=10\n","deed: #sents=10, #labels=10\n","\n","=== CAMPER TEST ===\n","Accuracy: 30.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.250     0.200     0.222         5\n","           2      0.333     0.400     0.364         5\n","\n","    accuracy                          0.300        10\n","   macro avg      0.292     0.300     0.293        10\n","weighted avg      0.292     0.300     0.293        10\n","\n","\n","=== CONVICTION TEST ===\n","Accuracy: 70.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.400     0.571         5\n","           2      0.625     1.000     0.769         5\n","\n","    accuracy                          0.700        10\n","   macro avg      0.812     0.700     0.670        10\n","weighted avg      0.812     0.700     0.670        10\n","\n","\n","=== DEED TEST ===\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.833     1.000     0.909         5\n","           2      1.000     0.800     0.889         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n"]}]},{"cell_type":"code","source":["import joblib\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","def load_test_sentences(path):\n","    return [L.strip() for L in open(path, encoding=\"utf-8\") if L.strip() and not L.lstrip().startswith(\"#\")]\n","\n","def load_gold_labels(path):\n","    return [int(L.strip()) for L in open(path, encoding=\"utf-8\") if L.strip() in (\"1\",\"2\")]\n","\n","test_sents = load_test_sentences(\"camper_test.txt\")\n","gold       = load_gold_labels(    \"result_camper_test.txt\")\n","\n","# load original (non-augmented) stacked pipeline\n","pipe_camper = joblib.load(\"camper_stack_pipe.joblib\")\n","\n","preds = pipe_camper.predict(test_sents)\n","print(\"CAMPER non-augmented TEST Accuracy:\", f\"{accuracy_score(gold, preds):.2%}\")\n","print(classification_report(gold, preds, digits=3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fot-G41B1ezi","executionInfo":{"status":"ok","timestamp":1746421549784,"user_tz":300,"elapsed":4999,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"25d4a079-1f01-41b9-a6cc-9168fec2fe9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["CAMPER non-augmented TEST Accuracy: 70.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.667     0.800     0.727         5\n","           2      0.750     0.600     0.667         5\n","\n","    accuracy                          0.700        10\n","   macro avg      0.708     0.700     0.697        10\n","weighted avg      0.708     0.700     0.697        10\n","\n"]}]},{"cell_type":"code","source":["# ─── Imports ─────────────────────────────────────────────────────────────────────────\n","from sentence_transformers import SentenceTransformer\n","import numpy as np\n","import joblib\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import GridSearchCV, cross_val_score\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# ─── Load & Embed Helpers ──────────────────────────────────────────────────────────\n","embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","\n","def load_data(path):\n","    sents, labs = [], []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            parts = line.strip().split(None,1)\n","            if len(parts)==2 and parts[0] in (\"1\",\"2\"):\n","                labs.append(int(parts[0]))\n","                sents.append(parts[1])\n","    return sents, labs\n","\n","def load_test_sents(path):\n","    return [L.strip() for L in open(path,encoding=\"utf-8\") if L.strip() and not L.startswith(\"#\")]\n","\n","def load_gold(path):\n","    return [int(L.strip()) for L in open(path,encoding=\"utf-8\") if L.strip() in (\"1\",\"2\")]\n","\n","# ─── Main Loop ─────────────────────────────────────────────────────────────────────\n","words = [\"camper\",\"conviction\",\"deed\"]\n","test_size = 10  # we know our synthetic tests each have 10 sentences\n","\n","for word in words:\n","    print(f\"\\n=== {word.upper()} ===\")\n","    # 1) Load (optionally augmented) data\n","    sents, labs = load_data(f\"{word}.txt\")\n","    # If you want augmentation, uncomment the next two lines:\n","    # sents, labs = synonym_augment(sents, labs, n_aug=2)\n","    print(f\"Training on {len(sents)} examples\")\n","\n","    # 2) Embed all training sentences\n","    X = embedder.encode(sents, convert_to_numpy=True)\n","    y = np.array(labs)\n","\n","    # 3) Hyperparameter search for MLP hidden layer size\n","    param_grid = {\n","        \"hidden_layer_sizes\": [(50,), (100,), (50,50)],\n","        \"alpha\": [1e-4, 1e-3],\n","    }\n","    grid = GridSearchCV(MLPClassifier(max_iter=1000, random_state=42),\n","                        param_grid, cv=5, n_jobs=1, scoring=\"accuracy\")\n","    grid.fit(X, y)\n","    print(\" Best MLP params:\", grid.best_params_, \"CV:\", f\"{grid.best_score_:.3f}\")\n","\n","    # 4) Final MLP on full data, save\n","    mlp = grid.best_estimator_\n","    mlp.fit(X, y)\n","    joblib.dump(mlp, f\"{word}_mlp_sbert.joblib\")\n","\n","    # 5) Evaluation on synthetic test\n","    test_sents = load_test_sents(f\"{word}_test.txt\")\n","    test_gold  = load_gold(   f\"result_{word}_test.txt\")\n","    X_test     = embedder.encode(test_sents, convert_to_numpy=True)\n","    preds      = mlp.predict(X_test)\n","    acc        = accuracy_score(test_gold, preds)\n","    print(f\" Synthetic TEST accuracy: {acc:.2%}\")\n","    print(classification_report(test_gold, preds, digits=3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B0XsmVvl2Ccq","executionInfo":{"status":"ok","timestamp":1746422084492,"user_tz":300,"elapsed":29987,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"54574f20-75a6-41c9-d474-9d193e1f6f32"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== CAMPER ===\n","Training on 52 examples\n"," Best MLP params: {'alpha': 0.0001, 'hidden_layer_sizes': (50,)} CV: 0.831\n"," Synthetic TEST accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","=== CONVICTION ===\n","Training on 40 examples\n"," Best MLP params: {'alpha': 0.0001, 'hidden_layer_sizes': (50,)} CV: 0.975\n"," Synthetic TEST accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.800     0.889         5\n","           2      0.833     1.000     0.909         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","=== DEED ===\n","Training on 40 examples\n"," Best MLP params: {'alpha': 0.0001, 'hidden_layer_sizes': (50, 50)} CV: 0.775\n"," Synthetic TEST accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n"]}]},{"cell_type":"code","source":["import joblib\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","def load_test_sentences(path):\n","    \"\"\"Read unlabeled test sentences, skipping blank/comment lines.\"\"\"\n","    with open(path, encoding=\"utf-8\") as f:\n","        return [l.strip() for l in f if l.strip() and not l.lstrip().startswith(\"#\")]\n","\n","def load_gold_labels(path):\n","    \"\"\"Read gold labels (1 or 2) from a file, skipping any non-numeric lines.\"\"\"\n","    labs = []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for l in f:\n","            tok = l.strip()\n","            if tok in (\"1\",\"2\"):\n","                labs.append(int(tok))\n","    return labs\n","\n","def evaluate_model(model_path, test_txt, gold_txt):\n","    \"\"\"\n","    Loads a model and test files, runs predict, and prints metrics.\n","\n","    :param model_path: str path to your .joblib model\n","    :param test_txt:    str path to the test sentences file\n","    :param gold_txt:    str path to the gold labels file\n","    \"\"\"\n","    # Load model\n","    model = joblib.load(model_path)\n","\n","    # Load data\n","    sents = load_test_sentences(test_txt)\n","    gold  = load_gold_labels(gold_txt)\n","\n","    # Predict\n","    preds = model.predict(sents)\n","\n","    # Report\n","    print(f\"\\n=== Evaluating {model_path} on {test_txt} ===\")\n","    print(f\"Test size: {len(sents)} sentences\")\n","    print(f\"Accuracy : {accuracy_score(gold, preds):.2%}\\n\")\n","    print(classification_report(gold, preds, digits=3))\n","\n","\n","if __name__ == \"__main__\":\n","    # Example usage on your “new” synthetic tests:\n","    evaluate_model(\"camper_mlp_sbert.joblib\",      \"camper_new_test.txt\",      \"result_camper_new_test.txt\")\n","    evaluate_model(\"conviction_mlp_sbert.joblib\", \"conviction_new_test.txt\", \"result_conviction_new_test.txt\")\n","    evaluate_model(\"deed_mlp_sbert.joblib\",        \"deed_new_test.txt\",        \"result_deed_new_test.txt\")\n","\n","    # On Tuesday you can swap in the real Canvas files, e.g.:\n","    # evaluate_model(\"camper_mlp_sbert.joblib\",      \"camper_test.txt\",      \"result_camper_YourName.txt\")\n","    # evaluate_model(\"conviction_mlp_sbert.joblib\", \"conviction_test.txt\", \"result_conviction_YourName.txt\")\n","    # evaluate_model(\"deed_mlp_sbert.joblib\",        \"deed_test.txt\",        \"result_deed_YourName.txt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":564},"id":"inu-gyEZ6Eng","executionInfo":{"status":"error","timestamp":1746422850532,"user_tz":300,"elapsed":1950,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"c7652ec9-9eba-440a-e61e-7da745996a19"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"Expected 2D array, got 1D array instead:\narray=['She backed the camper into the campsite’s narrow alleyway.'\n 'At summer camp, every camper learns to canoe and tie knots.'\n 'The camper’s battery died after we forgot to turn off the lights.'\n 'Each camper must sign in before breakfast service.'\n 'We spotted a vintage Airstream camper on the beach road.'\n 'The campers cheered as the archery instructor demonstrated proper form.'\n 'After hours on the trail, the group set up their camper for the night.'\n 'A day-camp camper sprained her ankle during the nature hike.'\n 'He installed solar panels on his off-road camper conversion.'\n 'The junior campers painted their cabins with bright colors.'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-116-5c740e74fc05>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Example usage on your “new” synthetic tests:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"camper_mlp_sbert.joblib\"\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;34m\"camper_new_test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;34m\"result_camper_new_test.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"conviction_mlp_sbert.joblib\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"conviction_new_test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"result_conviction_new_test.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"deed_mlp_sbert.joblib\"\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;34m\"deed_new_test.txt\"\u001b[0m\u001b[0;34m,\u001b[0m        \u001b[0;34m\"result_deed_new_test.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-116-5c740e74fc05>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(model_path, test_txt, gold_txt)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# Report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \"\"\"\n\u001b[1;32m   1181\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0;34m\"\"\"Private predict method with optional input validation\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass_fast\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \"\"\"\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0;31m# Initialize first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                         \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                     )\n\u001b[0;32m-> 1093\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kind\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"USV\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=['She backed the camper into the campsite’s narrow alleyway.'\n 'At summer camp, every camper learns to canoe and tie knots.'\n 'The camper’s battery died after we forgot to turn off the lights.'\n 'Each camper must sign in before breakfast service.'\n 'We spotted a vintage Airstream camper on the beach road.'\n 'The campers cheered as the archery instructor demonstrated proper form.'\n 'After hours on the trail, the group set up their camper for the night.'\n 'A day-camp camper sprained her ankle during the nature hike.'\n 'He installed solar panels on his off-road camper conversion.'\n 'The junior campers painted their cabins with bright colors.'].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."]}]},{"cell_type":"code","source":["# ─── Evaluation Helpers ─────────────────────────────────────────────────────────────\n","import joblib\n","import numpy as np\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","\n","def load_test_sentences(path):\n","    with open(path, encoding=\"utf-8\") as f:\n","        return [l.strip() for l in f if l.strip() and not l.lstrip().startswith(\"#\")]\n","\n","def load_gold_labels(path):\n","    return [int(l.strip()) for l in open(path, encoding=\"utf-8\") if l.strip() in (\"1\",\"2\")]\n","\n","def evaluate_mlp(model_path, test_txt, gold_txt):\n","    # Load model and test data\n","    mlp = joblib.load(model_path)\n","    sents = load_test_sentences(test_txt)\n","    gold  = load_gold_labels(gold_txt)\n","    # Embed before predicting\n","    X_test = embedder.encode(sents, convert_to_numpy=True)\n","    preds  = mlp.predict(X_test)\n","    # Report\n","    print(f\"\\n=== {model_path} on {test_txt} ===\")\n","    print(f\"Test size: {len(sents)} sentences\")\n","    print(f\"Accuracy : {accuracy_score(gold, preds):.2%}\\n\")\n","    print(classification_report(gold, preds, digits=3))\n","\n","# ─── Run evaluation on the new synthetic tests ──────────────────────────────────────\n","evaluate_mlp(\"camper_mlp_sbert.joblib\",      \"camper_new_test.txt\",      \"result_camper_new_test.txt\")\n","evaluate_mlp(\"conviction_mlp_sbert.joblib\", \"conviction_new_test.txt\", \"result_conviction_new_test.txt\")\n","evaluate_mlp(\"deed_mlp_sbert.joblib\",        \"deed_new_test.txt\",        \"result_deed_new_test.txt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N8W9Zw1P64od","executionInfo":{"status":"ok","timestamp":1746502435446,"user_tz":300,"elapsed":1561,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"39364956-4902-44bc-b89d-a3cbdf3f678d"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== camper_mlp_sbert.joblib on camper_new_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 80.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.600     0.750         5\n","           2      0.714     1.000     0.833         5\n","\n","    accuracy                          0.800        10\n","   macro avg      0.857     0.800     0.792        10\n","weighted avg      0.857     0.800     0.792        10\n","\n","\n","=== conviction_mlp_sbert.joblib on conviction_new_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 100.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","=== deed_mlp_sbert.joblib on deed_new_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 90.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      0.833     1.000     0.909         5\n","           2      1.000     0.800     0.889         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n"]}]},{"cell_type":"code","source":["# ─── Hyperparameter Tuning for the CAMPER MLP on SBERT Embeddings ───────────────────\n","from sentence_transformers import SentenceTransformer\n","import numpy as np\n","import joblib\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# 1) Load & embed camper training data\n","def load_data(path):\n","    sents, labs = [], []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            parts = line.strip().split(None,1)\n","            if len(parts)==2 and parts[0] in (\"1\",\"2\"):\n","                labs.append(int(parts[0]))\n","                sents.append(parts[1])\n","    return sents, labs\n","\n","train_sents, train_labels = load_data(\"camper.txt\")\n","embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","X_train = embedder.encode(train_sents, convert_to_numpy=True)\n","y_train = np.array(train_labels)\n","\n","# 2) Define a more extensive grid\n","param_grid = {\n","    \"hidden_layer_sizes\": [(25,), (50,), (100,), (50,50), (100,50)],\n","    \"alpha\": [1e-5, 1e-4, 1e-3],\n","    \"learning_rate_init\": [1e-4, 5e-4, 1e-3],\n","}\n","\n","# 3) Run GridSearchCV\n","grid = GridSearchCV(\n","    MLPClassifier(max_iter=2000, random_state=42),\n","    param_grid,\n","    cv=5,\n","    n_jobs=1,\n","    scoring=\"accuracy\"\n",")\n","grid.fit(X_train, y_train)\n","\n","print(\"Best parameters for CAMPER MLP:\", grid.best_params_)\n","print(\"Best CV accuracy        :\", f\"{grid.best_score_:.3f}\")\n","\n","# 4) Retrain final model with best params and save\n","best_mlp = grid.best_estimator_\n","best_mlp.fit(X_train, y_train)\n","joblib.dump(best_mlp, \"camper_mlp_sbert_tuned.joblib\")\n","\n","# 5) Evaluate on the synthetic test set\n","def load_test_sents(path):\n","    return [l.strip() for l in open(path, encoding=\"utf-8\") if l.strip() and not l.startswith(\"#\")]\n","\n","def load_gold(path):\n","    return [int(l.strip()) for l in open(path, encoding=\"utf-8\") if l.strip() in (\"1\",\"2\")]\n","\n","test_sents = load_test_sents(\"camper_new_test.txt\")\n","test_gold  = load_gold(\"result_camper_new_test.txt\")\n","X_test     = embedder.encode(test_sents, convert_to_numpy=True)\n","preds      = best_mlp.predict(X_test)\n","\n","print(\"\\n=== CAMPER Tuned MLP Synthetic Test ===\")\n","print(\"Accuracy :\", f\"{accuracy_score(test_gold, preds):.2%}\")\n","print(classification_report(test_gold, preds, digits=3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AaGae1a27bHV","executionInfo":{"status":"ok","timestamp":1746423257320,"user_tz":300,"elapsed":154082,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"d8ef5153-392e-4d63-cc78-0122490abce9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best parameters for CAMPER MLP: {'alpha': 1e-05, 'hidden_layer_sizes': (50,), 'learning_rate_init': 0.0001}\n","Best CV accuracy        : 0.849\n","\n","=== CAMPER Tuned MLP Synthetic Test ===\n","Accuracy : 80.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.600     0.750         5\n","           2      0.714     1.000     0.833         5\n","\n","    accuracy                          0.800        10\n","   macro avg      0.857     0.800     0.792        10\n","weighted avg      0.857     0.800     0.792        10\n","\n"]}]},{"cell_type":"code","source":["# ─── Setup ───────────────────────────────────────────────────────────────────────\n","!pip install -q -U sentence-transformers nltk\n","import nltk\n","nltk.download(\"wordnet\")\n","nltk.download(\"omw-1.4\")\n","import numpy as np\n","from sentence_transformers import SentenceTransformer\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score, classification_report\n","import joblib\n","from nltk.corpus import wordnet as wn\n","import random\n","\n","# ─── Synonym Augmentation ────────────────────────────────────────────────────────\n","def synonym_augment(sents, labels, n_aug=2):\n","    def augment_sent(sent):\n","        words = sent.split()\n","        new_sents = []\n","        for _ in range(n_aug):\n","            aug = []\n","            for w in words:\n","                syns = wn.synsets(w)\n","                lemmas = {l.name().replace(\"_\", \" \") for s in syns for l in s.lemmas() if l.name().lower() != w.lower()}\n","                if lemmas:\n","                    aug.append(random.choice(list(lemmas)))\n","                else:\n","                    aug.append(w)\n","            new_sents.append(\" \".join(aug))\n","        return new_sents\n","\n","    aug_sents, aug_labels = [], []\n","    for sent, label in zip(sents, labels):\n","        new_versions = augment_sent(sent)\n","        aug_sents.extend(new_versions)\n","        aug_labels.extend([label] * len(new_versions))\n","    return sents + aug_sents, labels + aug_labels\n","\n","# ─── Data Loaders ────────────────────────────────────────────────────────────────\n","def load_data(path):\n","    sents, labs = [], []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            parts = line.strip().split(None, 1)\n","            if len(parts) == 2 and parts[0] in (\"1\", \"2\"):\n","                labs.append(int(parts[0]))\n","                sents.append(parts[1])\n","    return sents, labs\n","\n","def load_test_sents(path):\n","    return [L.strip() for L in open(path, encoding=\"utf-8\") if L.strip() and not L.startswith(\"#\")]\n","\n","def load_gold(path):\n","    return [int(L.strip()) for L in open(path, encoding=\"utf-8\") if L.strip() in (\"1\", \"2\")]\n","\n","# ─── MLP Pipeline with Augmentation and SBERT ─────────────────────────────────────\n","from sklearn.pipeline import Pipeline\n","\n","print(\"\\n=== Improving CAMPER ===\")\n","sents, labels = load_data(\"camper.txt\")\n","sents_aug, labels_aug = synonym_augment(sents, labels, n_aug=2)\n","print(\"Original:\", len(sents), \"Augmented:\", len(sents_aug))\n","\n","embedder = SentenceTransformer(\"all-MiniLM-L12-v2\")\n","X_train = embedder.encode(sents_aug, convert_to_numpy=True)\n","y_train = np.array(labels_aug)\n","\n","param_grid = {\n","    \"hidden_layer_sizes\": [(50,), (100,), (50, 50), (100, 50)],\n","    \"alpha\": [1e-4, 1e-5, 1e-6],\n","}\n","grid = GridSearchCV(MLPClassifier(max_iter=1500, random_state=42), param_grid, cv=5, n_jobs=-1, scoring=\"accuracy\")\n","grid.fit(X_train, y_train)\n","\n","print(\" Best MLP params:\", grid.best_params_, \"CV:\", f\"{grid.best_score_:.3f}\")\n","\n","best_model = grid.best_estimator_\n","joblib.dump(best_model, \"camper_mlp_sbert_aug.joblib\")\n","\n","# ─── Evaluation ──────────────────────────────────────────────────────────────────\n","test_sents = load_test_sents(\"camper_new_test.txt\")\n","test_labels = load_gold(\"result_camper_new_test.txt\")\n","X_test = embedder.encode(test_sents, convert_to_numpy=True)\n","preds = best_model.predict(X_test)\n","\n","print(\"\\n=== CAMPER MLP + SBERT (Augmented) TEST ===\")\n","print(\"Accuracy:\", f\"{accuracy_score(test_labels, preds):.2%}\")\n","print(classification_report(test_labels, preds, digits=3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":979,"referenced_widgets":["e2aef6561a2a434c9a9977c48d168905","6a1131fe7d4f4f70a10452757722a469","52f25ef211364d14854afee7bfa583c0","c60e39146f0e4521ac2a97dafe3feee6","8aee71a1f76742069b1aa0aab6887b94","06d5df3f8b424377a159fc9820f9d408","3db5e0288dd84f82968c5b00debd30dc","7d05dc2ec3784509af1cbe0918c7879e","2f82559008c448a1b028971245385130","c0da02308f3b4dcd9e1ae908755ed22e","1ef45e58544c427bae53388295e1fa32","72a0d339c18c4bd7baa18c9dc2d421e3","7a8c85ee2d674fc88f71a6456bb2b7f4","5f4124847de94032a3151e31f94f2195","e3a691ef12cd4b9ba731eff9c5794e21","7c381e786b52471884e5bbe0313702f4","aeb5a65b77cf40e3b7c4b455fc2813f4","c6fa59bf785849229c064afa1bff6c9d","a4ee6d1d14094401ba4ff7b5f17ade10","882bbcf9e4234efeb388a2b43e6efd74","4e6666c748bc44d1badcfffb03d6ac99","dc9c948de8a64e0ba00179b7ebe6ed46","8b8282393fdf4326a4f796b5d768c39a","dfdbc1c40b28495e8922348cdc313228","2fd6d4da38bb4f5dba8d08556b1d06b7","e65c00d265444634b523bdd15ea77520","f5c616bc62c249b4a9c89869fac30b7c","d56d92eed85f4a63a11531f05211e84e","c3ebb119ab0b49179661e39871607b84","582ff85b19764f86a1caf4751317ed2d","eb636833c13f4aaebbc2799dc353364b","54b9fb0c077f4083ba0241baf8d047e4","eabd79997a024e56aadca46d42690d11","8f3a2d9f207f46359bb6a9555aa44ae7","9722870c0cf24a47a3c386c475346039","2e54be1f814340e9b9d8fbabcc74e160","067fbf2862e8442898f6ae91561e2863","325c31f6ae0c4f879073194bfe57b65b","8ce5070989754e46a89a0c69fd0f126c","389a2678e67d491fab53dae1f9b21f3b","65c1237961d847ed8006c0e1874b5f78","60999e2c74e74da98128777c0f48b394","ffe17880f4a143d3a34e56134026570e","da6e646e88a44e57a4e6160815c8f7ff","fd4bb4228eed43c48d785dfd2280dc5c","ee6dd10c40d24454b547863f45813210","c49d284a32ff41a4b569494d38674b2e","f10b7876ba3c464dbe483114fe61179a","1eebe580c793400595e32e40448e7d45","d89169fac22e404dae51fa564e05303c","c269c1ce992a4933a77a5e78a687953d","43e08efa964f4aa5a572bc635db41b63","87759f0b579c4299adc5e9897b2700da","07609d889c0848c187647f7cc7c8d9e3","832b407b5e4e4335a9843c1d638eb4a6","ca070066a4884658ad140dbc582141b7","ceb5aa89099640b9ad855de251d51e46","d14a59a4123849528ebcb40c5b2b4b25","e1f623f7efa246e7a917e62efaa7f667","bcaeb5bc8b9b4254838a80f5061cd5ac","8e0b7f12904e4bd4a668f046d9ec1ae6","a282f3eebfc142159aecf6e4f704413c","684bebbe281a48e9bfb2879ebd234640","395a8a3987d14b0aa157cb956641c7a2","dfffe6c323bb4cc8a2932a6fbbf31d2a","dde3af8c433342edb11d3899d37e7856","a272b0fa8fc242ce93c16ccddb8667a3","f08d1e2030af4516978d78c5ffb39b75","f33f2b200318432891554fae89824762","c7acf09214d947f78d3a37bc90f063f3","eea375d0ffae45aea50b91e3dbd9ee43","0234b6b2e8e549d2888d64dc80d0ba19","33e665e2feb64edeb851d56b0a9693ad","fb87a066d6f548128daa6c19e75dc229","6c133545204b4197b79e42b5aad5c593","1cbc87fa4b554f859ee34280deedaa08","51f670de832d440e9b701cb02cdd6eac","910a619f7ce9433b93ff887c4eae93f7","52744d6d61f9454fa9a86f2963b752dc","451d29ca2679474e90aa08d5dcca294f","d41ab5e05360451799b1c3e5ce75c885","e06aaeaa78194435983595b3761ec32c","44a9c2af273847bfbbbf4a51983eabdc","8368476b389c40d884d4d27a02e4e943","02112283cdc44eaab75e502fb02145fd","0888ca81d8c8461592cac1cdb79c0068","2ca013dbc146417baf19a58c869c58ad","0c0bd5fffb4c484191b77dcf0946367f","fa312a7826bd4177b6f29b3e546f1f5e","618f41780eac44f89af3c6d69259da7c","84c0d4011bf5445886e028148286cd65","98ef057a8593467ab5ac47d42a962c20","55aca91a721143f2a812cb075281691c","af41ed3bcd6a4b1daefd0e13af7a29c8","b34edaccd9c84558b802b05453d4feb7","562157ce6a9d466f9dad74744f5b21e9","be71680502884e058cc422c0944b71e1","d07f36784f5e4dcfb7a73aa94b86ba55","766f08533b9d45e29af10cc834a45e8e","e032417d203245fe95d72598fb364ae7","e7eb250a1f294cff856d73ae79979bcc","8b304b474c994703a60fbb5494fc1874","b8be33e15ebe461d936a20340cc21fc3","8f5376faa05e49778fe82ef7b52c25e0","7196c323255c47adb5f36af7d36f1352","cbd097cf678c417fa1d6fcca1f7b193a","e17f3f58c6a548be87da670a1b5f0416","8a199c61fef7464b9c28b475e831b7aa","c90ec151b70445d48a57c34c04be9046","a5359c42601240fc80a83d2728347268","b408784d57b64d25b9d3a75b10454850","471a321aca9f47b2bfb3a3f26ca974b5","632a9be231c84a519f50363c3a453aa5","660a72738dd74a2b8b62e367a94a445c","a14d0c53791c4838bd51f442fbd0381d","7ce8913510d64fae8c63b80a705ee23a","a8465dad544b459ba0cab1ef037f6389","9b1034ce65d74b4f8e42f86036ae926d","7fc026d0d502438384518b84fbe7d0b2","3a7d877dc5c948ec81825e731bf6722e","f5b9e80797cd4b5f934303f92ed17bc6"]},"id":"NNf3468WYMw6","executionInfo":{"status":"ok","timestamp":1746430828725,"user_tz":300,"elapsed":178730,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"518cc021-3c1f-4b6a-8fe9-6add1034c839"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0m"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["\n","=== Improving CAMPER ===\n","Original: 52 Augmented: 156\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2aef6561a2a434c9a9977c48d168905"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72a0d339c18c4bd7baa18c9dc2d421e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b8282393fdf4326a4f796b5d768c39a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f3a2d9f207f46359bb6a9555aa44ae7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fd4bb4228eed43c48d785dfd2280dc5c"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ca070066a4884658ad140dbc582141b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/352 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a272b0fa8fc242ce93c16ccddb8667a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"910a619f7ce9433b93ff887c4eae93f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa312a7826bd4177b6f29b3e546f1f5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e032417d203245fe95d72598fb364ae7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b408784d57b64d25b9d3a75b10454850"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":[" Best MLP params: {'alpha': 0.0001, 'hidden_layer_sizes': (100,)} CV: 0.903\n","\n","=== CAMPER MLP + SBERT (Augmented) TEST ===\n","Accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n"]}]},{"cell_type":"code","source":["# Creates new test sets and label files for camper, conviction, and deed\n","\n","test_data = {\n","    \"camper\": {\n","        \"sents\": [\n","            \"The seasoned camper pitched his tent under the stars.\",\n","            \"Every camper received a safety whistle before the hike.\",\n","            \"She was a happy camper until the rain started pouring.\",\n","            \"The campground assigned a plot to each registered camper.\",\n","            \"The camper filled his canteen at the freshwater spring.\",\n","            \"The luxury camper included a built-in kitchenette and bathroom.\",\n","            \"They hauled their camper across state lines every summer.\",\n","            \"A snowstorm stranded the couple in their camper overnight.\",\n","            \"The camper’s fuel tank needed to be refilled at the next stop.\",\n","            \"Their camper was custom-built for off-grid adventures.\",\n","        ],\n","        \"labels\": [2, 2, 2, 2, 2, 1, 1, 1, 1, 1]\n","    },\n","    \"conviction\": {\n","        \"sents\": [\n","            \"Her voice trembled but was filled with conviction.\",\n","            \"He held his beliefs with deep personal conviction.\",\n","            \"The speech was delivered with unwavering conviction.\",\n","            \"You could hear the conviction in his words.\",\n","            \"The candidate’s conviction won over many voters.\",\n","            \"The court overturned the original conviction after new evidence surfaced.\",\n","            \"He is appealing his conviction on the grounds of misconduct.\",\n","            \"The judge cited prior conviction as a reason for the sentence.\",\n","            \"DNA testing led to his wrongful conviction being dismissed.\",\n","            \"The prosecutor pushed for a swift conviction.\",\n","        ],\n","        \"labels\": [1, 1, 1, 1, 1, 2, 2, 2, 2, 2]\n","    },\n","    \"deed\": {\n","        \"sents\": [\n","            \"She was honored for her brave deed during the rescue.\",\n","            \"His final deed was to donate everything to charity.\",\n","            \"No good deed goes unnoticed in this town.\",\n","            \"That heroic deed saved three lives.\",\n","            \"Their kind deed inspired others to help.\",\n","            \"The deed listed both owners as joint tenants.\",\n","            \"He brought the property deed to the lawyer.\",\n","            \"The original deed was filed in 1978.\",\n","            \"They disputed the name on the deed.\",\n","            \"She inherited the deed to the estate.\",\n","        ],\n","        \"labels\": [2, 2, 2, 2, 2, 1, 1, 1, 1, 1]\n","    }\n","}\n","\n","for word, data in test_data.items():\n","    # Write sentence file\n","    with open(f\"{word}_newer_test.txt\", \"w\", encoding=\"utf-8\") as f_out:\n","        for line in data[\"sents\"]:\n","            f_out.write(line + \"\\n\")\n","\n","    # Write label file\n","    with open(f\"result_{word}_newer_test.txt\", \"w\", encoding=\"utf-8\") as f_out:\n","        for label in data[\"labels\"]:\n","            f_out.write(str(label) + \"\\n\")\n","\n","print(\"Test and label files created for camper, conviction, and deed.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yb8TEt4xZh7I","executionInfo":{"status":"ok","timestamp":1746430995982,"user_tz":300,"elapsed":69,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"618e21d3-7185-47cb-df82-39a89ff9fe54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test and label files created for camper, conviction, and deed.\n"]}]},{"cell_type":"code","source":["# ─── Run evaluation on the new synthetic tests ──────────────────────────────────────\n","evaluate_mlp(\"camper_mlp_sbert.joblib\",      \"camper_new_test.txt\",      \"result_camper_new_test.txt\")\n","evaluate_mlp(\"conviction_mlp_sbert.joblib\", \"conviction_new_test.txt\", \"result_conviction_new_test.txt\")\n","evaluate_mlp(\"deed_mlp_sbert.joblib\",        \"deed_new_test.txt\",        \"result_deed_new_test.txt\")"],"metadata":{"id":"nvj8inccaAyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Run these after generating the *_newer_test.txt files and loading your trained models\n","\n","evaluate_mlp(\"camper_mlp_sbert_aug.joblib\", \"camper_newer_test.txt\", \"result_camper_newer_test.txt\")\n","evaluate_mlp(\"conviction_mlp_sbert.joblib\", \"conviction_newer_test.txt\", \"result_conviction_newer_test.txt\")\n","evaluate_mlp(\"deed_mlp_sbert.joblib\", \"deed_newer_test.txt\", \"result_deed_newer_test.txt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ab5JL6l5Z1zt","executionInfo":{"status":"ok","timestamp":1746431144955,"user_tz":300,"elapsed":814,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"8bb86611-2668-4d58-9228-4e8f592d0080"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== camper_mlp_sbert_aug.joblib on camper_newer_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 30.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      0.375     0.600     0.462         5\n","           2      0.000     0.000     0.000         5\n","\n","    accuracy                          0.300        10\n","   macro avg      0.188     0.300     0.231        10\n","weighted avg      0.188     0.300     0.231        10\n","\n","\n","=== conviction_mlp_sbert.joblib on conviction_newer_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 100.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","=== deed_mlp_sbert.joblib on deed_newer_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 10.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      0.167     0.200     0.182         5\n","           2      0.000     0.000     0.000         5\n","\n","    accuracy                          0.100        10\n","   macro avg      0.083     0.100     0.091        10\n","weighted avg      0.083     0.100     0.091        10\n","\n"]}]},{"cell_type":"code","source":["import os\n","from glob import glob\n","\n","def auto_evaluate_mlp(word, model_file=None):\n","    \"\"\"Evaluate all test/result file pairs for a given word using a saved model.\"\"\"\n","    if model_file is None:\n","        model_file = f\"{word}_mlp_sbert.joblib\"\n","    if not os.path.exists(model_file):\n","        raise FileNotFoundError(f\"Model file not found: {model_file}\")\n","\n","    # Find all matching *_<word>_test.txt files (e.g., conviction_test.txt, conviction_newer_test.txt)\n","    test_files = [f for f in glob(f\"*{word}*test.txt\") if not f.startswith(\"result_\")]\n","\n","    for test_path in test_files:\n","        result_path = f\"result_{os.path.basename(test_path)}\"\n","        if not os.path.exists(result_path):\n","            print(f\"⚠️  No matching label file found for: {result_path}\")\n","            continue\n","        print(f\"\\n=== Running model on: {test_path} ===\")\n","        evaluate_mlp(model_file, test_path, result_path)\n","\n","\n","# Example usage:\n","auto_evaluate_mlp(\"conviction\")\n","# Or later:\n","# auto_evaluate_mlp(\"camper\")\n","# auto_evaluate_mlp(\"deed\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D0mSahVVbbLs","executionInfo":{"status":"ok","timestamp":1746502469389,"user_tz":300,"elapsed":1166,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"4b38d34b-4c54-45c3-e4f8-345dc55b5302"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== Running model on: sample_conviction_test.txt ===\n","\n","=== conviction_mlp_sbert.joblib on sample_conviction_test.txt ===\n","Test size: 4 sentences\n","Accuracy : 100.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         1\n","           2      1.000     1.000     1.000         3\n","\n","    accuracy                          1.000         4\n","   macro avg      1.000     1.000     1.000         4\n","weighted avg      1.000     1.000     1.000         4\n","\n","\n","=== Running model on: conviction_test.txt ===\n","\n","=== conviction_mlp_sbert.joblib on conviction_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 90.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.800     0.889         5\n","           2      0.833     1.000     0.909         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","=== Running model on: conviction_new_test.txt ===\n","\n","=== conviction_mlp_sbert.joblib on conviction_new_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 100.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","=== Running model on: conviction_newer_test.txt ===\n","\n","=== conviction_mlp_sbert.joblib on conviction_newer_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 90.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.800     0.889         5\n","           2      0.833     1.000     0.909         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","=== Running model on: conviction_hard_test.txt ===\n","\n","=== conviction_mlp_sbert.joblib on conviction_hard_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 60.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.429     0.600         7\n","           2      0.429     1.000     0.600         3\n","\n","    accuracy                          0.600        10\n","   macro avg      0.714     0.714     0.600        10\n","weighted avg      0.829     0.600     0.600        10\n","\n"]}]},{"cell_type":"code","source":["evaluate_mlp(\"conviction_mlp_sbert.joblib\", \"conviction_hard_test.txt\", \"result_conviction_hard_test.txt\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cFeVboZc4vh","executionInfo":{"status":"ok","timestamp":1746431874876,"user_tz":300,"elapsed":486,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"c13293a7-4998-4ad8-9f12-8f5b0dd9271a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== conviction_mlp_sbert.joblib on conviction_hard_test.txt ===\n","Test size: 10 sentences\n","Accuracy : 40.00%\n","\n","              precision    recall  f1-score   support\n","\n","           1      0.000     0.000     0.000         5\n","           2      0.444     0.800     0.571         5\n","\n","    accuracy                          0.400        10\n","   macro avg      0.222     0.400     0.286        10\n","weighted avg      0.222     0.400     0.286        10\n","\n"]}]},{"cell_type":"code","source":["import os\n","import numpy as np\n","import joblib\n","from sklearn.cluster import KMeans\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics import accuracy_score, classification_report\n","from collections import Counter, defaultdict\n","\n","# Load training data\n","def load_labeled_data(path):\n","    sents, labs = [], []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            parts = line.strip().split(None, 1)\n","            if len(parts) == 2 and parts[0] in (\"1\", \"2\"):\n","                labs.append(int(parts[0]))\n","                sents.append(parts[1])\n","    return sents, labs\n","\n","# Load unlabeled test sentences\n","def load_test_sentences(path):\n","    with open(path, encoding=\"utf-8\") as f:\n","        return [line.strip() for line in f if line.strip() and not line.startswith(\"#\")]\n","\n","# Load test labels\n","def load_gold_labels(path):\n","    with open(path, encoding=\"utf-8\") as f:\n","        return [int(line.strip()) for line in f if line.strip() in (\"1\", \"2\")]\n","\n","# Train KMeans WSD model and evaluate on all test files for a given word\n","def run_unsupervised_wsd(word, embedder):\n","    print(f\"\\n=== {word.upper()} ===\")\n","\n","    # Load training data and embed\n","    train_path = f\"{word}.txt\"\n","    train_sents, train_labels = load_labeled_data(train_path)\n","    X_train = embedder.encode(train_sents, convert_to_numpy=True)\n","\n","    # Train KMeans on sentence embeddings\n","    km = KMeans(n_clusters=2, random_state=42, n_init=10)\n","    km.fit(X_train)\n","    cluster_labels = km.labels_\n","\n","    # Map each cluster to the majority sense label\n","    cluster_to_sense = {}\n","    for c in [0, 1]:\n","        sense = Counter(l for l, k in zip(train_labels, cluster_labels) if k == c).most_common(1)[0][0]\n","        cluster_to_sense[c] = sense\n","\n","    # Evaluate on all matching test files\n","    for fname in os.listdir():\n","        if fname.startswith(word) and fname.endswith(\".txt\") and not fname.startswith(\"result_\"):\n","            test_sents = load_test_sentences(fname)\n","            result_name = f\"result_{fname}\"\n","            if os.path.exists(result_name):\n","                gold = load_gold_labels(result_name)\n","                X_test = embedder.encode(test_sents, convert_to_numpy=True)\n","                test_clusters = km.predict(X_test)\n","                preds = [cluster_to_sense[c] for c in test_clusters]\n","\n","                print(f\"\\n=== {word.upper()} KMeans on {fname} ===\")\n","                print(f\"Accuracy: {accuracy_score(gold, preds):.2%}\")\n","                print(classification_report(gold, preds, digits=3))\n","            else:\n","                print(f\"⚠️  No matching label file for: {result_name}\")\n","\n","# Run for all words\n","embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","for word in [\"camper\", \"conviction\", \"deed\"]:\n","    run_unsupervised_wsd(word, embedder)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5vkqJh_rfmsa","executionInfo":{"status":"ok","timestamp":1746432595741,"user_tz":300,"elapsed":6649,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"a7319430-5e44-4db1-e2e8-d289842b8ac1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== CAMPER ===\n","⚠️  No matching label file for: result_camper.txt\n","\n","=== CAMPER KMeans on camper_test.txt ===\n","Accuracy: 70.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.400     0.571         5\n","           2      0.625     1.000     0.769         5\n","\n","    accuracy                          0.700        10\n","   macro avg      0.812     0.700     0.670        10\n","weighted avg      0.812     0.700     0.670        10\n","\n","\n","=== CAMPER KMeans on camper_new_test.txt ===\n","Accuracy: 70.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.400     0.571         5\n","           2      0.625     1.000     0.769         5\n","\n","    accuracy                          0.700        10\n","   macro avg      0.812     0.700     0.670        10\n","weighted avg      0.812     0.700     0.670        10\n","\n","\n","=== CAMPER KMeans on camper_newer_test.txt ===\n","Accuracy: 30.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.000     0.000     0.000         5\n","           2      0.375     0.600     0.462         5\n","\n","    accuracy                          0.300        10\n","   macro avg      0.188     0.300     0.231        10\n","weighted avg      0.188     0.300     0.231        10\n","\n","\n","=== CONVICTION ===\n","⚠️  No matching label file for: result_conviction.txt\n","\n","=== CONVICTION KMeans on conviction_test.txt ===\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.800     0.889         5\n","           2      0.833     1.000     0.909         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","=== CONVICTION KMeans on conviction_new_test.txt ===\n","Accuracy: 80.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.600     0.750         5\n","           2      0.714     1.000     0.833         5\n","\n","    accuracy                          0.800        10\n","   macro avg      0.857     0.800     0.792        10\n","weighted avg      0.857     0.800     0.792        10\n","\n","\n","=== CONVICTION KMeans on conviction_newer_test.txt ===\n","Accuracy: 60.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.200     0.333         5\n","           2      0.556     1.000     0.714         5\n","\n","    accuracy                          0.600        10\n","   macro avg      0.778     0.600     0.524        10\n","weighted avg      0.778     0.600     0.524        10\n","\n","\n","=== CONVICTION KMeans on conviction_hard_test.txt ===\n","Accuracy: 40.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.000     0.000     0.000         5\n","           2      0.444     0.800     0.571         5\n","\n","    accuracy                          0.400        10\n","   macro avg      0.222     0.400     0.286        10\n","weighted avg      0.222     0.400     0.286        10\n","\n","\n","=== DEED ===\n","⚠️  No matching label file for: result_deed.txt\n","\n","=== DEED KMeans on deed_test.txt ===\n","Accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","=== DEED KMeans on deed_new_test.txt ===\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.833     1.000     0.909         5\n","           2      1.000     0.800     0.889         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","=== DEED KMeans on deed_newer_test.txt ===\n","Accuracy: 20.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.286     0.400     0.333         5\n","           2      0.000     0.000     0.000         5\n","\n","    accuracy                          0.200        10\n","   macro avg      0.143     0.200     0.167        10\n","weighted avg      0.143     0.200     0.167        10\n","\n"]}]},{"cell_type":"markdown","source":["# Train Script"],"metadata":{"id":"ZAipdwtghN5V"}},{"cell_type":"code","source":["import joblib\n","import numpy as np\n","import nltk\n","import re\n","from nltk.corpus import wordnet as wn\n","from nltk.stem import WordNetLemmatizer\n","from nltk import word_tokenize\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sentence_transformers import SentenceTransformer\n","\n","# Download required NLTK data\n","nltk.download(\"punkt\")\n","nltk.download('punkt_tab')\n","nltk.download(\"wordnet\")\n","nltk.download(\"omw-1.4\")\n","\n","embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","lemmatizer = WordNetLemmatizer()\n","\n","# ─── Preprocessing & Feature Extractors ─────────────────────────────\n","class LemmaTransformer(BaseEstimator, TransformerMixin):\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        return [\" \".join(lemmatizer.lemmatize(w) for w in word_tokenize(s.lower())) for s in X]\n","\n","class WordNetOverlap(BaseEstimator, TransformerMixin):\n","    def __init__(self, word): self.word = word\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        senses = wn.synsets(self.word, pos=wn.NOUN)[:2]\n","        gloss_sets = [set(word_tokenize(s.definition().lower())) for s in senses]\n","        feats = []\n","        for sent in X:\n","            toks = set(word_tokenize(sent.lower()))\n","            feats.append([len(toks & gloss_sets[0]), len(toks & gloss_sets[1])])\n","        return np.array(feats)\n","\n","class WindowFeatures(BaseEstimator, TransformerMixin):\n","    def __init__(self, word): self.word = word\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        feats = []\n","        for sent in X:\n","            toks = word_tokenize(sent.lower())\n","            idx = toks.index(self.word) if self.word in toks else -1\n","            window = toks[max(0, idx-2): idx+3]\n","            feats.append([len(window), sum(1 for t in window if t in (\"the\", \"a\", \"an\"))])\n","        return np.array(feats)\n","\n","class GlossSimilarity(BaseEstimator, TransformerMixin):\n","    def __init__(self, word):\n","        self.word = word\n","\n","    def fit(self, X, y=None): return self\n","\n","    def transform(self, X):\n","        embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # reload here, avoid storing\n","        senses = wn.synsets(self.word, pos=wn.NOUN)[:2]\n","        gloss_vecs = embedder.encode([s.definition() for s in senses])\n","        sent_vecs = embedder.encode(X)\n","        return np.array([[np.dot(s, gloss_vecs[0]), np.dot(s, gloss_vecs[1])] for s in sent_vecs])\n","\n","\n","# ─── Data Loading & Augmentation ────────────────────────────────────\n","def load_data(path):\n","    sents, labs = [], []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            parts = line.strip().split(None, 1)\n","            if len(parts) == 2 and parts[0] in (\"1\", \"2\"):\n","                labs.append(int(parts[0]))\n","                sents.append(parts[1])\n","    return sents, labs\n","\n","def synonym_augment(sents, labels, n_aug=2):\n","    aug_sents, aug_labels = [], []\n","    for s, l in zip(sents, labels):\n","        tokens = word_tokenize(s)\n","        for i, word in enumerate(tokens):\n","            syns = wn.synsets(word)\n","            if syns:\n","                lemmas = set(lemma.replace(\"_\", \" \") for syn in syns for lemma in syn.lemma_names())\n","                for lemma in list(lemmas)[:n_aug]:\n","                    new = tokens[:i] + [lemma] + tokens[i+1:]\n","                    aug_sents.append(\" \".join(new))\n","                    aug_labels.append(l)\n","    return sents + aug_sents, labels + aug_labels\n","\n","# ─── Training Scripts ───────────────────────────────────────────────\n","def build_conviction_model():\n","    sents, labels = load_data(\"conviction_extended.txt\")\n","    X = embedder.encode(sents)\n","    model = MLPClassifier(hidden_layer_sizes=(50,), alpha=0.0001, max_iter=1000, random_state=42)\n","    model.fit(X, labels)\n","    joblib.dump(model, \"conviction_mlp_sbert.joblib\")\n","    print(\"✅ Conviction model saved.\")\n","\n","def build_camper_model():\n","    sents, labels = load_data(\"camper_extended.txt\")\n","    s_aug, l_aug = synonym_augment(sents, labels, n_aug=2)\n","    X = embedder.encode(s_aug)\n","    model = MLPClassifier(hidden_layer_sizes=(50, 50), alpha=0.0001, max_iter=1000, random_state=42)\n","    model.fit(X, l_aug)\n","    joblib.dump(model, \"camper_mlp_sbert_aug.joblib\")\n","    print(\"✅ Camper model saved.\")\n","\n","def build_deed_model():\n","    sents, labels = load_data(\"deed_extended.txt\")\n","    s_aug, l_aug = synonym_augment(sents, labels, n_aug=3)\n","    union = FeatureUnion([\n","        (\"tf_w\", TfidfVectorizer(analyzer=\"word\", ngram_range=(1,3), min_df=1)),\n","        (\"tf_c\", TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=1)),\n","        (\"wnov\", WordNetOverlap(\"deed\")),\n","        (\"wind\", WindowFeatures(\"deed\")),\n","        (\"glos\", GlossSimilarity(\"deed\")),\n","    ])\n","    pipe = Pipeline([\n","        (\"lemma\", LemmaTransformer()),\n","        (\"feat\", union),\n","        (\"clf\", RandomForestClassifier(n_estimators=200, random_state=42)),\n","    ])\n","    pipe.fit(s_aug, l_aug)\n","    joblib.dump(pipe, \"deed_stack_pipe.joblib\")\n","    print(\"✅ Deed model saved.\")\n","\n","if __name__ == \"__main__\":\n","    build_conviction_model()\n","    build_camper_model()\n","    build_deed_model()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jPZTJwrhhNYA","executionInfo":{"status":"ok","timestamp":1746483923411,"user_tz":300,"elapsed":140645,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"3ee3cef5-4383-462a-bf1f-c6bf4b8ad00f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["✅ Conviction model saved.\n","✅ Camper model saved.\n","✅ Deed model saved.\n"]}]},{"cell_type":"markdown","source":["# Eval Script"],"metadata":{"id":"y1czZQuHip_G"}},{"cell_type":"code","source":["import os\n","import re\n","import joblib\n","import numpy as np\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Load embedder only once\n","embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","\n","# === Helper Functions ===\n","def load_test_sentences(path):\n","    with open(path, encoding=\"utf-8\") as f:\n","        return [line.strip() for line in f if line.strip() and not line.startswith(\"#\")]\n","\n","def load_gold_labels(path):\n","    with open(path, encoding=\"utf-8\") as f:\n","        return [int(line.strip()) for line in f if line.strip() in (\"1\", \"2\")]\n","\n","def evaluate_model(model_path, test_path, label_path, debug=False):\n","    sents = load_test_sentences(test_path)\n","    gold = load_gold_labels(label_path)\n","    model = joblib.load(model_path)\n","\n","    if \"deed\" in model_path.lower():\n","        X_test = sents\n","    else:\n","        X_test = embedder.encode(sents, convert_to_numpy=True)\n","\n","    preds = model.predict(X_test)\n","\n","    print(f\"\\n=== {os.path.basename(model_path)} on {os.path.basename(test_path)} ===\")\n","    print(f\"Test size: {len(sents)} sentences\")\n","    print(\"Accuracy:\", f\"{accuracy_score(gold, preds):.2%}\")\n","    print(classification_report(gold, preds, digits=3))\n","\n","    if debug:\n","        print(\"\\nSentence-by-sentence predictions:\")\n","        for i, (s, g, p) in enumerate(zip(sents, gold, preds)):\n","            correctness = \"✅\" if g == p else \"❌\"\n","            print(f\"{i+1:02d}. [{correctness}] GOLD: {g} | PRED: {p} | {s}\")\n","\n","# === Main Evaluation Loop ===\n","def run_all_tests_for_word(word, debug = False):\n","    model_file_map = {\n","        \"camper\": \"camper_mlp_sbert_aug.joblib\",\n","        \"conviction\": \"conviction_mlp_sbert.joblib\",\n","        \"deed\": \"deed_stack_pipe.joblib\",\n","    }\n","\n","    model_path = model_file_map[word.lower()]\n","    pattern = re.compile(rf\"{word}(_\\w+)?_test\\.txt$\")\n","    all_files = os.listdir(\".\")\n","\n","    for test_file in sorted(f for f in all_files if pattern.fullmatch(f)):\n","        base = re.sub(r\"\\.txt$\", \"\", test_file)\n","        label_file = f\"result_{base}.txt\"\n","\n","        if not os.path.exists(label_file):\n","            print(f\"\\n⚠️  No matching label file found for: {label_file}\")\n","            continue\n","        if debug:\n","            evaluate_model(model_path, test_file, label_file, debug=True)\n","        else:\n","            evaluate_model(model_path, test_file, label_file)\n","\n","# Example usage:\n","if __name__ == \"__main__\":\n","    for w in [\"camper\", \"conviction\", \"deed\"]:\n","        print(f\"\\n=== {w.upper()} ===\")\n","        run_all_tests_for_word(w, debug = True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"883meKosivEJ","executionInfo":{"status":"ok","timestamp":1746485545062,"user_tz":300,"elapsed":8434,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"a9927160-cf5d-4d3b-fae1-de5a9c39c2f2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== CAMPER ===\n","\n","=== camper_mlp_sbert_aug.joblib on camper_new_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 80.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.800     0.800     0.800         5\n","           2      0.800     0.800     0.800         5\n","\n","    accuracy                          0.800        10\n","   macro avg      0.800     0.800     0.800        10\n","weighted avg      0.800     0.800     0.800        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | She backed the camper into the campsite’s narrow alleyway.\n","02. [✅] GOLD: 2 | PRED: 2 | At summer camp, every camper learns to canoe and tie knots.\n","03. [✅] GOLD: 1 | PRED: 1 | The camper’s battery died after we forgot to turn off the lights.\n","04. [✅] GOLD: 2 | PRED: 2 | Each camper must sign in before breakfast service.\n","05. [✅] GOLD: 1 | PRED: 1 | We spotted a vintage Airstream camper on the beach road.\n","06. [✅] GOLD: 2 | PRED: 2 | The campers cheered as the archery instructor demonstrated proper form.\n","07. [❌] GOLD: 1 | PRED: 2 | After hours on the trail, the group set up their camper for the night.\n","08. [✅] GOLD: 2 | PRED: 2 | A day-camp camper sprained her ankle during the nature hike.\n","09. [✅] GOLD: 1 | PRED: 1 | He installed solar panels on his off-road camper conversion.\n","10. [❌] GOLD: 2 | PRED: 1 | The junior campers painted their cabins with bright colors.\n","\n","=== camper_mlp_sbert_aug.joblib on camper_newer_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 2 | PRED: 2 | The seasoned camper pitched his tent under the stars.\n","02. [✅] GOLD: 2 | PRED: 2 | Every camper received a safety whistle before the hike.\n","03. [✅] GOLD: 2 | PRED: 2 | She was a happy camper until the rain started pouring.\n","04. [✅] GOLD: 2 | PRED: 2 | The campground assigned a plot to each registered camper.\n","05. [✅] GOLD: 2 | PRED: 2 | The camper filled his canteen at the freshwater spring.\n","06. [✅] GOLD: 1 | PRED: 1 | The luxury camper included a built-in kitchenette and bathroom.\n","07. [✅] GOLD: 1 | PRED: 1 | They hauled their camper across state lines every summer.\n","08. [✅] GOLD: 1 | PRED: 1 | A snowstorm stranded the couple in their camper overnight.\n","09. [✅] GOLD: 1 | PRED: 1 | The camper’s fuel tank needed to be refilled at the next stop.\n","10. [✅] GOLD: 1 | PRED: 1 | Their camper was custom-built for off-grid adventures.\n","\n","=== camper_mlp_sbert_aug.joblib on camper_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.800     0.889         5\n","           2      0.833     1.000     0.909         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [❌] GOLD: 1 | PRED: 2 | The family packed their bags into the camper before heading to Yellowstone for the weekend.\n","02. [✅] GOLD: 2 | PRED: 2 | As a summer camper at the wildlife retreat, she learned how to identify animal tracks.\n","03. [✅] GOLD: 1 | PRED: 1 | He renovated his old school bus to become a comfortable roadside camper.\n","04. [✅] GOLD: 2 | PRED: 2 | The campers gathered around the fire pit to roast marshmallows.\n","05. [✅] GOLD: 1 | PRED: 1 | We rented a luxury camper complete with a kitchenette and shower.\n","06. [✅] GOLD: 2 | PRED: 2 | Each camper must complete the swimming proficiency test before the lake trip.\n","07. [✅] GOLD: 1 | PRED: 1 | The company unveiled their new electric camper model at the trade show.\n","08. [✅] GOLD: 2 | PRED: 2 | The teenage camper forgot to pack her hiking boots for the forest excursion.\n","09. [✅] GOLD: 1 | PRED: 1 | A camper towed the boat trailer down the highway.\n","10. [✅] GOLD: 2 | PRED: 2 | Counselors ensured every camper had sunscreen before going to the beach.\n","\n","=== CONVICTION ===\n","\n","=== conviction_mlp_sbert.joblib on conviction_hard_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 60.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.429     0.600         7\n","           2      0.429     1.000     0.600         3\n","\n","    accuracy                          0.600        10\n","   macro avg      0.714     0.714     0.600        10\n","weighted avg      0.829     0.600     0.600        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | Her conviction never wavered, even in the courtroom.\n","02. [✅] GOLD: 2 | PRED: 2 | The conviction was overturned after a lengthy appeal.\n","03. [❌] GOLD: 1 | PRED: 2 | He spoke with conviction about the injustice he suffered.\n","04. [✅] GOLD: 2 | PRED: 2 | After years in prison, his conviction still defines him.\n","05. [❌] GOLD: 1 | PRED: 2 | It was a speech full of conviction and legal terminology.\n","06. [✅] GOLD: 1 | PRED: 1 | They admired her conviction, though some thought it delusional.\n","07. [✅] GOLD: 2 | PRED: 2 | The conviction rate has declined due to lack of evidence.\n","08. [✅] GOLD: 1 | PRED: 1 | Despite no evidence, her moral conviction was absolute.\n","09. [❌] GOLD: 1 | PRED: 2 | The law requires evidence beyond reasonable conviction.\n","10. [❌] GOLD: 1 | PRED: 2 | That conviction in her tone made the judge reconsider.\n","\n","=== conviction_mlp_sbert.joblib on conviction_new_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | Her conviction that honesty is the best policy guided every decision.\n","02. [✅] GOLD: 2 | PRED: 2 | The exoneration came only after the conviction was overturned.\n","03. [✅] GOLD: 1 | PRED: 1 | I admire his conviction that music can bridge cultural divides.\n","04. [✅] GOLD: 2 | PRED: 2 | A second conviction for DUIs led to a five-year license suspension.\n","05. [✅] GOLD: 1 | PRED: 1 | They argued vehemently, each with equal conviction in their point.\n","06. [✅] GOLD: 2 | PRED: 2 | The judge handed down the maximum sentence following the conviction.\n","07. [✅] GOLD: 1 | PRED: 1 | Her conviction in free speech never wavered, even under pressure.\n","08. [✅] GOLD: 2 | PRED: 2 | The high-profile conviction made headlines across the country.\n","09. [✅] GOLD: 1 | PRED: 1 | Despite doubts, her conviction propelled her to start the charity.\n","10. [✅] GOLD: 2 | PRED: 2 | He appealed the conviction on grounds of improper jury instructions.\n","\n","=== conviction_mlp_sbert.joblib on conviction_newer_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.800     0.889         5\n","           2      0.833     1.000     0.909         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | Her voice trembled but was filled with conviction.\n","02. [✅] GOLD: 1 | PRED: 1 | He held his beliefs with deep personal conviction.\n","03. [✅] GOLD: 1 | PRED: 1 | The speech was delivered with unwavering conviction.\n","04. [✅] GOLD: 1 | PRED: 1 | You could hear the conviction in his words.\n","05. [❌] GOLD: 1 | PRED: 2 | The candidate’s conviction won over many voters.\n","06. [✅] GOLD: 2 | PRED: 2 | The court overturned the original conviction after new evidence surfaced.\n","07. [✅] GOLD: 2 | PRED: 2 | He is appealing his conviction on the grounds of misconduct.\n","08. [✅] GOLD: 2 | PRED: 2 | The judge cited prior conviction as a reason for the sentence.\n","09. [✅] GOLD: 2 | PRED: 2 | DNA testing led to his wrongful conviction being dismissed.\n","10. [✅] GOLD: 2 | PRED: 2 | The prosecutor pushed for a swift conviction.\n","\n","=== conviction_mlp_sbert.joblib on conviction_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.800     0.889         5\n","           2      0.833     1.000     0.909         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [❌] GOLD: 1 | PRED: 2 | His conviction in the existence of extraterrestrial life motivated his astronomy studies.\n","02. [✅] GOLD: 2 | PRED: 2 | After the trial, the press reported the senator’s conviction on corruption charges.\n","03. [✅] GOLD: 1 | PRED: 1 | Her conviction that laughter could improve mental health led her to start a comedy club.\n","04. [✅] GOLD: 2 | PRED: 2 | The murder conviction was overturned after new evidence proved the defendant’s innocence.\n","05. [✅] GOLD: 1 | PRED: 1 | Despite criticism, his conviction that art can change society never faltered.\n","06. [✅] GOLD: 2 | PRED: 2 | Following her conviction for shoplifting, she was ordered to perform community service.\n","07. [✅] GOLD: 1 | PRED: 1 | They spoke with conviction when presenting their environmental petition.\n","08. [✅] GOLD: 2 | PRED: 2 | The jury’s speedy conviction surprised many in the courtroom.\n","09. [✅] GOLD: 1 | PRED: 1 | Her conviction that technology can bridge cultural divides shaped her career path.\n","10. [✅] GOLD: 2 | PRED: 2 | The judge’s written opinion detailed the reasons for the defendant’s conviction.\n","\n","=== DEED ===\n","\n","=== deed_stack_pipe.joblib on deed_new_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | She signed the deed transferring ownership of the farmland.\n","02. [✅] GOLD: 2 | PRED: 2 | Volunteering at the shelter was his first good deed of the year.\n","03. [✅] GOLD: 1 | PRED: 1 | The notary public examined the deed for forgeries.\n","04. [✅] GOLD: 2 | PRED: 2 | Planting a tree in the community park is a simple deed anyone can do.\n","05. [✅] GOLD: 1 | PRED: 1 | They recorded the deed in the county archives.\n","06. [✅] GOLD: 2 | PRED: 2 | His courageous deed during the rescue earned him a commendation.\n","07. [✅] GOLD: 1 | PRED: 1 | Before closing, the bank required the deed of trust.\n","08. [✅] GOLD: 2 | PRED: 2 | Baking cookies for her neighbor was a kind deed that brightened his day.\n","09. [✅] GOLD: 1 | PRED: 1 | The deed poll officially changed her name.\n","10. [✅] GOLD: 2 | PRED: 2 | Filling sandbags before the flood was a heroic deed by the townspeople.\n","\n","=== deed_stack_pipe.joblib on deed_newer_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 2 | PRED: 2 | She was honored for her brave deed during the rescue.\n","02. [✅] GOLD: 2 | PRED: 2 | His final deed was to donate everything to charity.\n","03. [✅] GOLD: 2 | PRED: 2 | No good deed goes unnoticed in this town.\n","04. [✅] GOLD: 2 | PRED: 2 | That heroic deed saved three lives.\n","05. [✅] GOLD: 2 | PRED: 2 | Their kind deed inspired others to help.\n","06. [✅] GOLD: 1 | PRED: 1 | The deed listed both owners as joint tenants.\n","07. [✅] GOLD: 1 | PRED: 1 | He brought the property deed to the lawyer.\n","08. [✅] GOLD: 1 | PRED: 1 | The original deed was filed in 1978.\n","09. [✅] GOLD: 1 | PRED: 1 | They disputed the name on the deed.\n","10. [✅] GOLD: 1 | PRED: 1 | She inherited the deed to the estate.\n","\n","=== deed_stack_pipe.joblib on deed_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.833     1.000     0.909         5\n","           2      1.000     0.800     0.889         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | He presented the original deed to the cabin during the property closing.\n","02. [✅] GOLD: 2 | PRED: 2 | The volunteer’s good deed restored faith in humanity.\n","03. [✅] GOLD: 1 | PRED: 1 | They discovered a forged deed hidden in the archives of the courthouse.\n","04. [✅] GOLD: 2 | PRED: 2 | Saving the stray dog was a noble deed that inspired her neighbors.\n","05. [✅] GOLD: 1 | PRED: 1 | Before selling the mansion, she obtained a certified copy of the deed.\n","06. [✅] GOLD: 2 | PRED: 2 | His final deed of bravery earned him a posthumous medal.\n","07. [✅] GOLD: 1 | PRED: 1 | The deed of trust specified the lender’s security interest in the house.\n","08. [✅] GOLD: 2 | PRED: 2 | Donating his savings to the orphanage was his most memorable deed.\n","09. [✅] GOLD: 1 | PRED: 1 | The hospital required the deed transferring the land for a new wing.\n","10. [❌] GOLD: 2 | PRED: 1 | Cleaning up the beach after the storm was a generous deed by the volunteers.\n"]}]},{"cell_type":"markdown","source":["#  “cs5322s25.py” module"],"metadata":{"id":"UnePzuNO9Im1"}},{"cell_type":"code","source":["import os\n","import joblib\n","from sentence_transformers import SentenceTransformer\n","from train import LemmaTransformer, GlossSimilarity, WindowFeatures, WordNetOverlap\n","\n","def WSD_Test_camper(sentences):\n","    \"\"\"\n","    Takes a list of sentences containing 'camper' and returns predicted sense labels (1 or 2).\n","    Loads the SBERT embedder and camper model inside the function as required.\n","    \"\"\"\n","    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","    model = joblib.load(\"camper_mlp_sbert_aug.joblib\")\n","    embeddings = embedder.encode(sentences, convert_to_numpy=True)\n","    predictions = model.predict(embeddings)\n","    return predictions.tolist()\n","\n","def WSD_Test_conviction(sentences):\n","    \"\"\"\n","    Takes a list of sentences containing 'conviction' and returns predicted sense labels (1 or 2).\n","    Loads the SBERT embedder and conviction model inside the function.\n","    \"\"\"\n","    embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","    model = joblib.load(\"conviction_mlp_sbert.joblib\")\n","    embeddings = embedder.encode(sentences, convert_to_numpy=True)\n","    predictions = model.predict(embeddings)\n","    return predictions.tolist()\n","\n","def WSD_Test_deed(sentences):\n","    \"\"\"\n","    Takes a list of sentences containing 'deed' and returns predicted sense labels (1 or 2).\n","    Loads the pipeline model (which includes its own preprocessing).\n","    \"\"\"\n","    model = joblib.load(\"deed_stack_pipe.joblib\")\n","    predictions = model.predict(sentences)\n","    return predictions.tolist()\n","\n","def run_test(firstname, lastname):\n","    name_tag = f\"{firstname.lower()}{lastname.lower()}\"\n","    test_files = {\n","        \"camper\": \"camper_test.txt\",\n","        \"conviction\": \"conviction_test.txt\",\n","        \"deed\": \"deed_test.txt\",\n","    }\n","\n","    functions = {\n","        \"camper\": WSD_Test_camper,\n","        \"conviction\": WSD_Test_conviction,\n","        \"deed\": WSD_Test_deed,\n","    }\n","\n","    for word, file in test_files.items():\n","        if not os.path.exists(file):\n","            print(f\"Missing test file: {file}\")\n","            continue\n","\n","        # Load sentences\n","        with open(file, encoding=\"utf-8\") as f:\n","            sentences = [line.strip() for line in f if line.strip()]\n","\n","        # Run prediction\n","        print(f\"Predicting senses for {word}...\")\n","        results = functions[word](sentences)\n","\n","        # Save to file\n","        out_file = f\"result_{word}_{name_tag}.txt\"\n","        with open(out_file, \"w\", encoding=\"utf-8\") as f:\n","            for label in results:\n","                f.write(str(label) + \"\\n\")\n","\n","        print(f\"Saved results to: {out_file}\")\n","\n","\n","if __name__ == \"__main__\":\n","    run_test(\"Harley\", \"Gribble\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9zYbZLI89NRh","executionInfo":{"status":"ok","timestamp":1746497190526,"user_tz":300,"elapsed":3512,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"0bca78f6-c5d0-41f7-9f29-e619cb6c07c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicting senses for camper...\n","Saved results to: result_camper_harleygribble.txt\n","Predicting senses for conviction...\n","Saved results to: result_conviction_harleygribble.txt\n","Predicting senses for deed...\n","Saved results to: result_deed_harleygribble.txt\n"]}]},{"cell_type":"markdown","source":["## test.py"],"metadata":{"id":"0aDcFVoB9Qaa"}},{"cell_type":"code","source":["from cs5322s25 import WSD_Test_camper, WSD_Test_conviction, WSD_Test_deed\n","from train import LemmaTransformer, GlossSimilarity, WindowFeatures, WordNetOverlap\n","\n","# Example usage:\n","if __name__ == \"__main__\":\n","        print(WSD_Test_camper([\"They parked their camper at the lakeside.\", \"Each camper brought a sleeping bag.\"])) # expected 1, 2\n","        print(WSD_Test_conviction([\"He was convicted for murder.\", \"She spoke with great conviction.\"])) # expected 2, 1\n","        print(WSD_Test_deed([\"He signed the deed to the property.\", \"Her brave deed saved a child.\"])) # 1, 2\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vw54xY6T9T4H","executionInfo":{"status":"ok","timestamp":1746497198874,"user_tz":300,"elapsed":2470,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"8d8df884-3f0d-4e9c-d60d-a85ee1551a66"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[1, 2]\n","[2, 1]\n","[1, 2]\n"]}]},{"cell_type":"markdown","source":["# eval.py"],"metadata":{"id":"vNhPVPnGVHkz"}},{"cell_type":"code","source":["import os\n","import re\n","import joblib\n","import numpy as np\n","from sentence_transformers import SentenceTransformer\n","from sklearn.metrics import accuracy_score, classification_report\n","from train import LemmaTransformer, GlossSimilarity, WindowFeatures, WordNetOverlap\n","\n","# Load embedder only once\n","embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","\n","# === Helper Functions ===\n","def load_test_sentences(path):\n","    with open(path, encoding=\"utf-8\") as f:\n","        return [line.strip() for line in f if line.strip() and not line.startswith(\"#\")]\n","\n","def load_gold_labels(path):\n","    with open(path, encoding=\"utf-8\") as f:\n","        return [int(line.strip()) for line in f if line.strip() in (\"1\", \"2\")]\n","\n","def evaluate_model(model_path, test_path, label_path, debug=False):\n","    sents = load_test_sentences(test_path)\n","    gold = load_gold_labels(label_path)\n","    model = joblib.load(model_path)\n","\n","    if \"deed\" in model_path.lower():\n","        X_test = sents\n","    else:\n","        X_test = embedder.encode(sents, convert_to_numpy=True)\n","    # X_test = embedder.encode(sents, convert_to_numpy=True)\n","    preds = model.predict(X_test)\n","\n","    print(f\"\\n=== {os.path.basename(model_path)} on {os.path.basename(test_path)} ===\")\n","    print(f\"Test size: {len(sents)} sentences\")\n","    print(\"Accuracy:\", f\"{accuracy_score(gold, preds):.2%}\")\n","    print(classification_report(gold, preds, digits=3))\n","\n","    if debug:\n","        print(\"\\nSentence-by-sentence predictions:\")\n","        for i, (s, g, p) in enumerate(zip(sents, gold, preds)):\n","            correctness = \"✅\" if g == p else \"❌\"\n","            print(f\"{i+1:02d}. [{correctness}] GOLD: {g} | PRED: {p} | {s}\")\n","\n","# === Main Evaluation Loop ===\n","def run_all_tests_for_word(word, debug = False):\n","    model_file_map = {\n","        \"camper\": \"camper_mlp_sbert_aug.joblib\",\n","        \"conviction\": \"conviction_mlp_sbert.joblib\",\n","        \"deed\": \"deed_stack_pipe.joblib\"\n","        #\"deed\": \"deed_mlp_sbert.joblib\"\n","    }\n","\n","    model_path = model_file_map[word.lower()]\n","    pattern = re.compile(rf\"{word}(_\\w+)?_test\\.txt$\")\n","    all_files = os.listdir(\".\")\n","\n","    for test_file in sorted(f for f in all_files if pattern.fullmatch(f)):\n","        base = re.sub(r\"\\.txt$\", \"\", test_file)\n","        label_file = f\"result_{base}.txt\"\n","\n","        if not os.path.exists(label_file):\n","            print(f\"\\n⚠️  No matching label file found for: {label_file}\")\n","            continue\n","        if debug:\n","            evaluate_model(model_path, test_file, label_file, debug=True)\n","        else:\n","            evaluate_model(model_path, test_file, label_file)\n","\n","# Example usage:\n","if __name__ == \"__main__\":\n","    for w in [\"camper\", \"conviction\", \"deed\"]:\n","        print(f\"\\n=== {w.upper()} ===\")\n","        run_all_tests_for_word(w, debug = True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7gX_LXvDVHLT","executionInfo":{"status":"ok","timestamp":1746502768163,"user_tz":300,"elapsed":5033,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"76c399c7-71a5-4f1d-cdbe-dbf0090deccd"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== CAMPER ===\n","\n","=== camper_mlp_sbert_aug.joblib on camper_new_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 80.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.800     0.800     0.800         5\n","           2      0.800     0.800     0.800         5\n","\n","    accuracy                          0.800        10\n","   macro avg      0.800     0.800     0.800        10\n","weighted avg      0.800     0.800     0.800        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | She backed the camper into the campsite’s narrow alleyway.\n","02. [✅] GOLD: 2 | PRED: 2 | At summer camp, every camper learns to canoe and tie knots.\n","03. [✅] GOLD: 1 | PRED: 1 | The camper’s battery died after we forgot to turn off the lights.\n","04. [✅] GOLD: 2 | PRED: 2 | Each camper must sign in before breakfast service.\n","05. [✅] GOLD: 1 | PRED: 1 | We spotted a vintage Airstream camper on the beach road.\n","06. [✅] GOLD: 2 | PRED: 2 | The campers cheered as the archery instructor demonstrated proper form.\n","07. [❌] GOLD: 1 | PRED: 2 | After hours on the trail, the group set up their camper for the night.\n","08. [✅] GOLD: 2 | PRED: 2 | A day-camp camper sprained her ankle during the nature hike.\n","09. [✅] GOLD: 1 | PRED: 1 | He installed solar panels on his off-road camper conversion.\n","10. [❌] GOLD: 2 | PRED: 1 | The junior campers painted their cabins with bright colors.\n","\n","=== camper_mlp_sbert_aug.joblib on camper_newer_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 2 | PRED: 2 | The seasoned camper pitched his tent under the stars.\n","02. [✅] GOLD: 2 | PRED: 2 | Every camper received a safety whistle before the hike.\n","03. [✅] GOLD: 2 | PRED: 2 | She was a happy camper until the rain started pouring.\n","04. [✅] GOLD: 2 | PRED: 2 | The campground assigned a plot to each registered camper.\n","05. [✅] GOLD: 2 | PRED: 2 | The camper filled his canteen at the freshwater spring.\n","06. [✅] GOLD: 1 | PRED: 1 | The luxury camper included a built-in kitchenette and bathroom.\n","07. [✅] GOLD: 1 | PRED: 1 | They hauled their camper across state lines every summer.\n","08. [✅] GOLD: 1 | PRED: 1 | A snowstorm stranded the couple in their camper overnight.\n","09. [✅] GOLD: 1 | PRED: 1 | The camper’s fuel tank needed to be refilled at the next stop.\n","10. [✅] GOLD: 1 | PRED: 1 | Their camper was custom-built for off-grid adventures.\n","\n","=== camper_mlp_sbert_aug.joblib on camper_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.800     0.889         5\n","           2      0.833     1.000     0.909         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [❌] GOLD: 1 | PRED: 2 | The family packed their bags into the camper before heading to Yellowstone for the weekend.\n","02. [✅] GOLD: 2 | PRED: 2 | As a summer camper at the wildlife retreat, she learned how to identify animal tracks.\n","03. [✅] GOLD: 1 | PRED: 1 | He renovated his old school bus to become a comfortable roadside camper.\n","04. [✅] GOLD: 2 | PRED: 2 | The campers gathered around the fire pit to roast marshmallows.\n","05. [✅] GOLD: 1 | PRED: 1 | We rented a luxury camper complete with a kitchenette and shower.\n","06. [✅] GOLD: 2 | PRED: 2 | Each camper must complete the swimming proficiency test before the lake trip.\n","07. [✅] GOLD: 1 | PRED: 1 | The company unveiled their new electric camper model at the trade show.\n","08. [✅] GOLD: 2 | PRED: 2 | The teenage camper forgot to pack her hiking boots for the forest excursion.\n","09. [✅] GOLD: 1 | PRED: 1 | A camper towed the boat trailer down the highway.\n","10. [✅] GOLD: 2 | PRED: 2 | Counselors ensured every camper had sunscreen before going to the beach.\n","\n","=== CONVICTION ===\n","\n","=== conviction_mlp_sbert.joblib on conviction_hard_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 60.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.429     0.600         7\n","           2      0.429     1.000     0.600         3\n","\n","    accuracy                          0.600        10\n","   macro avg      0.714     0.714     0.600        10\n","weighted avg      0.829     0.600     0.600        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | Her conviction never wavered, even in the courtroom.\n","02. [✅] GOLD: 2 | PRED: 2 | The conviction was overturned after a lengthy appeal.\n","03. [❌] GOLD: 1 | PRED: 2 | He spoke with conviction about the injustice he suffered.\n","04. [✅] GOLD: 2 | PRED: 2 | After years in prison, his conviction still defines him.\n","05. [❌] GOLD: 1 | PRED: 2 | It was a speech full of conviction and legal terminology.\n","06. [✅] GOLD: 1 | PRED: 1 | They admired her conviction, though some thought it delusional.\n","07. [✅] GOLD: 2 | PRED: 2 | The conviction rate has declined due to lack of evidence.\n","08. [✅] GOLD: 1 | PRED: 1 | Despite no evidence, her moral conviction was absolute.\n","09. [❌] GOLD: 1 | PRED: 2 | The law requires evidence beyond reasonable conviction.\n","10. [❌] GOLD: 1 | PRED: 2 | That conviction in her tone made the judge reconsider.\n","\n","=== conviction_mlp_sbert.joblib on conviction_new_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | Her conviction that honesty is the best policy guided every decision.\n","02. [✅] GOLD: 2 | PRED: 2 | The exoneration came only after the conviction was overturned.\n","03. [✅] GOLD: 1 | PRED: 1 | I admire his conviction that music can bridge cultural divides.\n","04. [✅] GOLD: 2 | PRED: 2 | A second conviction for DUIs led to a five-year license suspension.\n","05. [✅] GOLD: 1 | PRED: 1 | They argued vehemently, each with equal conviction in their point.\n","06. [✅] GOLD: 2 | PRED: 2 | The judge handed down the maximum sentence following the conviction.\n","07. [✅] GOLD: 1 | PRED: 1 | Her conviction in free speech never wavered, even under pressure.\n","08. [✅] GOLD: 2 | PRED: 2 | The high-profile conviction made headlines across the country.\n","09. [✅] GOLD: 1 | PRED: 1 | Despite doubts, her conviction propelled her to start the charity.\n","10. [✅] GOLD: 2 | PRED: 2 | He appealed the conviction on grounds of improper jury instructions.\n","\n","=== conviction_mlp_sbert.joblib on conviction_newer_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.800     0.889         5\n","           2      0.833     1.000     0.909         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | Her voice trembled but was filled with conviction.\n","02. [✅] GOLD: 1 | PRED: 1 | He held his beliefs with deep personal conviction.\n","03. [✅] GOLD: 1 | PRED: 1 | The speech was delivered with unwavering conviction.\n","04. [✅] GOLD: 1 | PRED: 1 | You could hear the conviction in his words.\n","05. [❌] GOLD: 1 | PRED: 2 | The candidate’s conviction won over many voters.\n","06. [✅] GOLD: 2 | PRED: 2 | The court overturned the original conviction after new evidence surfaced.\n","07. [✅] GOLD: 2 | PRED: 2 | He is appealing his conviction on the grounds of misconduct.\n","08. [✅] GOLD: 2 | PRED: 2 | The judge cited prior conviction as a reason for the sentence.\n","09. [✅] GOLD: 2 | PRED: 2 | DNA testing led to his wrongful conviction being dismissed.\n","10. [✅] GOLD: 2 | PRED: 2 | The prosecutor pushed for a swift conviction.\n","\n","=== conviction_mlp_sbert.joblib on conviction_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     0.800     0.889         5\n","           2      0.833     1.000     0.909         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [❌] GOLD: 1 | PRED: 2 | His conviction in the existence of extraterrestrial life motivated his astronomy studies.\n","02. [✅] GOLD: 2 | PRED: 2 | After the trial, the press reported the senator’s conviction on corruption charges.\n","03. [✅] GOLD: 1 | PRED: 1 | Her conviction that laughter could improve mental health led her to start a comedy club.\n","04. [✅] GOLD: 2 | PRED: 2 | The murder conviction was overturned after new evidence proved the defendant’s innocence.\n","05. [✅] GOLD: 1 | PRED: 1 | Despite criticism, his conviction that art can change society never faltered.\n","06. [✅] GOLD: 2 | PRED: 2 | Following her conviction for shoplifting, she was ordered to perform community service.\n","07. [✅] GOLD: 1 | PRED: 1 | They spoke with conviction when presenting their environmental petition.\n","08. [✅] GOLD: 2 | PRED: 2 | The jury’s speedy conviction surprised many in the courtroom.\n","09. [✅] GOLD: 1 | PRED: 1 | Her conviction that technology can bridge cultural divides shaped her career path.\n","10. [✅] GOLD: 2 | PRED: 2 | The judge’s written opinion detailed the reasons for the defendant’s conviction.\n","\n","=== DEED ===\n","\n","=== deed_stack_pipe.joblib on deed_new_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | She signed the deed transferring ownership of the farmland.\n","02. [✅] GOLD: 2 | PRED: 2 | Volunteering at the shelter was his first good deed of the year.\n","03. [✅] GOLD: 1 | PRED: 1 | The notary public examined the deed for forgeries.\n","04. [✅] GOLD: 2 | PRED: 2 | Planting a tree in the community park is a simple deed anyone can do.\n","05. [✅] GOLD: 1 | PRED: 1 | They recorded the deed in the county archives.\n","06. [✅] GOLD: 2 | PRED: 2 | His courageous deed during the rescue earned him a commendation.\n","07. [✅] GOLD: 1 | PRED: 1 | Before closing, the bank required the deed of trust.\n","08. [✅] GOLD: 2 | PRED: 2 | Baking cookies for her neighbor was a kind deed that brightened his day.\n","09. [✅] GOLD: 1 | PRED: 1 | The deed poll officially changed her name.\n","10. [✅] GOLD: 2 | PRED: 2 | Filling sandbags before the flood was a heroic deed by the townspeople.\n","\n","=== deed_stack_pipe.joblib on deed_newer_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 100.00%\n","              precision    recall  f1-score   support\n","\n","           1      1.000     1.000     1.000         5\n","           2      1.000     1.000     1.000         5\n","\n","    accuracy                          1.000        10\n","   macro avg      1.000     1.000     1.000        10\n","weighted avg      1.000     1.000     1.000        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 2 | PRED: 2 | She was honored for her brave deed during the rescue.\n","02. [✅] GOLD: 2 | PRED: 2 | His final deed was to donate everything to charity.\n","03. [✅] GOLD: 2 | PRED: 2 | No good deed goes unnoticed in this town.\n","04. [✅] GOLD: 2 | PRED: 2 | That heroic deed saved three lives.\n","05. [✅] GOLD: 2 | PRED: 2 | Their kind deed inspired others to help.\n","06. [✅] GOLD: 1 | PRED: 1 | The deed listed both owners as joint tenants.\n","07. [✅] GOLD: 1 | PRED: 1 | He brought the property deed to the lawyer.\n","08. [✅] GOLD: 1 | PRED: 1 | The original deed was filed in 1978.\n","09. [✅] GOLD: 1 | PRED: 1 | They disputed the name on the deed.\n","10. [✅] GOLD: 1 | PRED: 1 | She inherited the deed to the estate.\n","\n","=== deed_stack_pipe.joblib on deed_test.txt ===\n","Test size: 10 sentences\n","Accuracy: 90.00%\n","              precision    recall  f1-score   support\n","\n","           1      0.833     1.000     0.909         5\n","           2      1.000     0.800     0.889         5\n","\n","    accuracy                          0.900        10\n","   macro avg      0.917     0.900     0.899        10\n","weighted avg      0.917     0.900     0.899        10\n","\n","\n","Sentence-by-sentence predictions:\n","01. [✅] GOLD: 1 | PRED: 1 | He presented the original deed to the cabin during the property closing.\n","02. [✅] GOLD: 2 | PRED: 2 | The volunteer’s good deed restored faith in humanity.\n","03. [✅] GOLD: 1 | PRED: 1 | They discovered a forged deed hidden in the archives of the courthouse.\n","04. [✅] GOLD: 2 | PRED: 2 | Saving the stray dog was a noble deed that inspired her neighbors.\n","05. [✅] GOLD: 1 | PRED: 1 | Before selling the mansion, she obtained a certified copy of the deed.\n","06. [✅] GOLD: 2 | PRED: 2 | His final deed of bravery earned him a posthumous medal.\n","07. [✅] GOLD: 1 | PRED: 1 | The deed of trust specified the lender’s security interest in the house.\n","08. [✅] GOLD: 2 | PRED: 2 | Donating his savings to the orphanage was his most memorable deed.\n","09. [✅] GOLD: 1 | PRED: 1 | The hospital required the deed transferring the land for a new wing.\n","10. [❌] GOLD: 2 | PRED: 1 | Cleaning up the beach after the storm was a generous deed by the volunteers.\n"]}]},{"cell_type":"markdown","source":["# train.py"],"metadata":{"id":"Zjxk2BPwVL15"}},{"cell_type":"code","source":["import joblib\n","import numpy as np\n","import nltk\n","import re\n","from nltk.corpus import wordnet as wn\n","from nltk.stem import WordNetLemmatizer\n","from nltk import word_tokenize\n","from sklearn.base import BaseEstimator, TransformerMixin\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.pipeline import Pipeline, FeatureUnion\n","from sentence_transformers import SentenceTransformer\n","\n","# Download required NLTK data\n","nltk.download(\"punkt\")\n","nltk.download('punkt_tab')\n","nltk.download(\"wordnet\")\n","nltk.download(\"omw-1.4\")\n","\n","embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n","lemmatizer = WordNetLemmatizer()\n","\n","# ─── Preprocessing & Feature Extractors ─────────────────────────────\n","class LemmaTransformer(BaseEstimator, TransformerMixin):\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        return [\" \".join(lemmatizer.lemmatize(w) for w in word_tokenize(s.lower())) for s in X]\n","\n","class WordNetOverlap(BaseEstimator, TransformerMixin):\n","    def __init__(self, word): self.word = word\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        senses = wn.synsets(self.word, pos=wn.NOUN)[:2]\n","        gloss_sets = [set(word_tokenize(s.definition().lower())) for s in senses]\n","        feats = []\n","        for sent in X:\n","            toks = set(word_tokenize(sent.lower()))\n","            feats.append([len(toks & gloss_sets[0]), len(toks & gloss_sets[1])])\n","        return np.array(feats)\n","\n","class WindowFeatures(BaseEstimator, TransformerMixin):\n","    def __init__(self, word): self.word = word\n","    def fit(self, X, y=None): return self\n","    def transform(self, X):\n","        feats = []\n","        for sent in X:\n","            toks = word_tokenize(sent.lower())\n","            idx = toks.index(self.word) if self.word in toks else -1\n","            window = toks[max(0, idx-2): idx+3]\n","            feats.append([len(window), sum(1 for t in window if t in (\"the\", \"a\", \"an\"))])\n","        return np.array(feats)\n","\n","class GlossSimilarity(BaseEstimator, TransformerMixin):\n","    def __init__(self, word):\n","        self.word = word\n","\n","    def fit(self, X, y=None): return self\n","\n","    def transform(self, X):\n","        embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")  # reload here, avoid storing\n","        senses = wn.synsets(self.word, pos=wn.NOUN)[:2]\n","        gloss_vecs = embedder.encode([s.definition() for s in senses])\n","        sent_vecs = embedder.encode(X)\n","        return np.array([[np.dot(s, gloss_vecs[0]), np.dot(s, gloss_vecs[1])] for s in sent_vecs])\n","\n","\n","# ─── Data Loading & Augmentation ────────────────────────────────────\n","def load_data(path):\n","    sents, labs = [], []\n","    with open(path, encoding=\"utf-8\") as f:\n","        for line in f:\n","            parts = line.strip().split(None, 1)\n","            if len(parts) == 2 and parts[0] in (\"1\", \"2\"):\n","                labs.append(int(parts[0]))\n","                sents.append(parts[1])\n","    return sents, labs\n","\n","def synonym_augment(sents, labels, n_aug=2):\n","    aug_sents, aug_labels = [], []\n","    for s, l in zip(sents, labels):\n","        tokens = word_tokenize(s)\n","        for i, word in enumerate(tokens):\n","            syns = wn.synsets(word)\n","            if syns:\n","                lemmas = set(lemma.replace(\"_\", \" \") for syn in syns for lemma in syn.lemma_names())\n","                for lemma in list(lemmas)[:n_aug]:\n","                    new = tokens[:i] + [lemma] + tokens[i+1:]\n","                    aug_sents.append(\" \".join(new))\n","                    aug_labels.append(l)\n","    return sents + aug_sents, labels + aug_labels\n","\n","# ─── Training Scripts ───────────────────────────────────────────────\n","def build_conviction_model():\n","    sents, labels = load_data(\"conviction_extended.txt\")\n","    X = embedder.encode(sents)\n","    model = MLPClassifier(hidden_layer_sizes=(50,), alpha=0.0001, max_iter=1000, random_state=42)\n","    model.fit(X, labels)\n","    joblib.dump(model, \"conviction_mlp_sbert.joblib\")\n","    print(\"Conviction model saved.\")\n","\n","def build_camper_model():\n","    sents, labels = load_data(\"camper_extended.txt\")\n","    s_aug, l_aug = synonym_augment(sents, labels, n_aug=2)\n","    X = embedder.encode(s_aug)\n","    model = MLPClassifier(hidden_layer_sizes=(50, 50), alpha=0.0001, max_iter=1000, random_state=42)\n","    model.fit(X, l_aug)\n","    joblib.dump(model, \"camper_mlp_sbert_aug.joblib\")\n","    print(\"Camper model saved.\")\n","\n","def build_deed_model():\n","    sents, labels = load_data(\"deed_extended.txt\")\n","    s_aug, l_aug = synonym_augment(sents, labels, n_aug=3)\n","    union = FeatureUnion([\n","        (\"tf_w\", TfidfVectorizer(analyzer=\"word\", ngram_range=(1,3), min_df=1)),\n","        (\"tf_c\", TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=1)),\n","        (\"wnov\", WordNetOverlap(\"deed\")),\n","        (\"wind\", WindowFeatures(\"deed\")),\n","        (\"glos\", GlossSimilarity(\"deed\")),\n","    ])\n","    pipe = Pipeline([\n","        (\"lemma\", LemmaTransformer()),\n","        (\"feat\", union),\n","        (\"clf\", RandomForestClassifier(n_estimators=200, random_state=42)),\n","    ])\n","    pipe.fit(s_aug, l_aug)\n","    joblib.dump(pipe, \"deed_stack_pipe.joblib\")\n","    print(\"Deed model saved.\")\n","\n","if __name__ == \"__main__\":\n","    build_conviction_model()\n","    build_camper_model()\n","    build_deed_model()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ceM765KVNxE","executionInfo":{"status":"ok","timestamp":1746502263029,"user_tz":300,"elapsed":134335,"user":{"displayName":"b1akp1astik","userId":"01865054174797146745"}},"outputId":"4d0f329d-2db6-4eeb-e3fb-d38ca99942bf"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Conviction model saved.\n","Camper model saved.\n","Deed model saved.\n"]}]}]}